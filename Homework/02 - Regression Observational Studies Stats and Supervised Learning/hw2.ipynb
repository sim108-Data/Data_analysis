{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 (HW2)\n",
    "\n",
    "---\n",
    "By the end of this homework we expect you to be able to:\n",
    "1. Preprocess data and make it amenable to statistical analysis and machine learning models;\n",
    "2. Train and test out-of-the-box machine learning models in Python;\n",
    "3. Carry out statistical hypothesis testing;\n",
    "4. Carry out simple multivariate regression analyses;\n",
    "5. Use techniques to control for covariates;\n",
    "---\n",
    "\n",
    "## Important Dates\n",
    "\n",
    "- Homework release: Fri 6 Nov 2020\n",
    "- **Homework due**: Fri 20 Nov 2020, 23:59\n",
    "- Grade release: Mon 30 Nov 2020\n",
    "\n",
    "---\n",
    "\n",
    "##  Some rules\n",
    "\n",
    "1. You are allowed to use any built-in Python library that comes with Anaconda. If you want to use an external library, you have to justify your choice.\n",
    "2. Make sure you use the data folder provided in the repository in **read-only** mode.\n",
    "3. Be sure to provide a textual description of your thought process, the assumptions you made, the solution you implemented, and explanations for your answers. A notebook that only has code cells will not suffice.\n",
    "4. For questions containing the **/Discuss:/** prefix, answer not with code, but with a textual explanation (in markdown).\n",
    "5. Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "6. Please write all your comments in English, and use meaningful variable names in your code. Your repo should have a single notebook (plus the required data files) in the master branch. If there are multiple notebooks present, we will **strictly** not grade anything.\n",
    "7. Also, be sure to hand in a fully-run and evaluated notebook. We will not run your notebook for you, we will grade it as is, which means that only the results contained in your evaluated code cells will be considered, and we will not see the results in unevaluated code cells. In order to check whether everything looks as intended, you can check the rendered notebook on the GitHub website once you have pushed your solution there.\n",
    "8. Make sure to print results or dataframes that confirm you have properly addressed the task.\n",
    "9. Lastly, the grading is done in the *double blind* mode, i.e., the TAs grades an anonymized version of your notebook, so make sure that your notebook **neither has your team name nor the names of the members**.\n",
    "\n",
    "## Context\n",
    "\n",
    "Publishing papers is a big part of the lives of [Ph.D. students](http://phdcomics.com/comics/archive.php?comicid=154), [post-docs](http://phdcomics.com/comics/archive.php?comicid=1744) and [professors](http://phdcomics.com/comics/archive.php?comicid=1051). \n",
    "In Computer Science, publishing happens mostly in conferences. What follows is a slight simplification of how these conferences decide which papers to accept and which papers to reject.\n",
    " \n",
    "Every year, scholars submit papers to prestigious conferences. The papers are then assigned to reviewers (usually around 3), who are other people from the same research community (respect thy neighbor!). Each reviewer weighs in on whether they believe the papers they were assigned are good or bad, and write a review, often along with a score (e.g. +3 Strong Accept, +2 Accept, +1 Weak Accept, 0 Borderline, …,  -3 Strong Reject). Then, in the end, \"special\" reviewers called, \"Area Chairs\" analyze all the reviews that were written for the same paper and decide what gets accepted and what gets rejected. Importantly, throughout this whole dance, reviewers and authors are anonymous. When you're reviewing a paper, you do not know who wrote it. And when you receive the review, you don't know who reviewed it. Because of that, we call this a double-blind reviewing process.\n",
    "\n",
    "An interesting development that has evolved in recent years is the rise of pre-prints. In previous times, researchers often exposed their research to the world only after it had been peer-reviewed and published in a conference or a journal. But recently researchers are much keener to let their ideas out into the world as soon as possible, and they publish their research before it has been approved to any conference or journal, by posting the research on so-called pre-print servers. The most common pre-print server for Computer Science, Physics, and Maths is called [arXiv](https://arxiv.org/), for Biology, an increasingly popular one is [bioRxiv](https://www.biorxiv.org/), for Psychology [psyArXiv](https://psyarxiv.com/) (they are not very creative with the names). Notice that pre-prints and peer-review are not mutually exclusive, in fact, usually, you publish your pre-print, and then you try to publish your work in a peer-reviewed setting.\n",
    "\n",
    "Overall, publishing pre-prints has many benefits. They make science more accessible and hasten the circulation of important results in the academic community. However, a big issue brought forth with pre-prints is that they often break the anonymity in the double-blind reviewing process. For instance, in machine learning, since most papers are published as pre-prints, it is often easy to figure out if the paper you are reviewing is from a famous researcher or a big company with prominent research scientists. From critics' viewpoint, knowing the authors of the papers you are reviewing can bias your reviews. If you know that a given author is famous, you'd be more inclined to take his or her word for granted. If the author is from an institution you’ve never heard about, you are more likely to doubt his or her findings.\n",
    "\n",
    "In this homework, we will take a data-driven deep dive into the world of academic publishing. Can you use your freshly acquired data-science skills to predict which papers are going to make the cut? Are your data analysis skills sharp enough to figure out whether the aforementioned concerns about pre-print issues are justified?\n",
    "\n",
    "\n",
    "## The data\n",
    "\n",
    "The data, whose source has been *\"double-blinded\"* from you, and which has been simplified a bit for the assignment, contains information about submissions to a prestigious machine learning conference called ICLR (pronounced “I-clear”). You can find the dataframe in the git repo for the homework (`./data/dataset_final.csv`). We provide a brief description of the fields you will encounter.\n",
    "\n",
    "- `year`: year the paper has been submitted to ICLR. Notice that we provide data for three years, 2018, 2019, and 2020.\n",
    "\n",
    "\n",
    "- `paper`: title of the paper.\n",
    "\n",
    "\n",
    "- `authors`: names of the authors separated by ;.\n",
    "\n",
    "\n",
    "- `ratings`: mean rating given to the paper by the reviewers.\n",
    "\n",
    "\n",
    "- `decisions`: either Accept if the paper was accepted, or Reject otherwise.\n",
    "\n",
    "\n",
    "- `institution`: institutions for each of the authors, separated by ;.\n",
    "\n",
    "\n",
    "- `csranking`: ranking of the institutions according to csrankings. The better the institution, the better the rank. Notice that, if a paper has more than 1 author, this field will contain multiple values, separated by ;. For institutions that are not in csrankings, the value will be -1.\n",
    "\n",
    "\n",
    "- `categories`: topical categories of the paper. Each number corresponds to a different category: (1) Theory, (2) Computer Vision, (3) Natural Language Processing, (4) Adversarial ML, (5) Generative Modeling, (7) Fairness, (8) Generalization, (9) Optimization, (10) Graphs, (11) Bayesian Methods, (0) Others. A paper may belong to multiple categories, separated by ;.\n",
    "\n",
    "\n",
    "- `authors_citations`: number of citations of each one of the authors, separated by ;.\n",
    "\n",
    "\n",
    "- `authors_publications`: number of publications by each one of the authors, separated by ;.\n",
    "\n",
    "\n",
    "- `authors_hindex`: h-index of each one of the authors, separated by ;. The h-index is an author-level metric that measures both the productivity and citation impact of the publications of a scientist or scholar. It is the maximum value $h$ such that the given author has published $h$ papers that have each been cited at least $h$ times.\n",
    "\n",
    "\n",
    "- `arxiv`: whether the paper was spotted in a pre-print server around the submission period.\n",
    "\n",
    "Also, notice that in this dataframe, when some piece of data was not available, -1 will be used as the value. For example, companies aren't a part of csrankings, so for people who work in big companies, the values are -1 in the field csranking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Step 1:_ Predicting paper ratings\n",
    "\n",
    "The first part of this homework poses a simple question: Can you predict the ratings the paper will receive given attributes related to its authors? To answer this question, we will build an ML pipeline from scratch, preprocessing the data, training a regression model, and then evaluating it.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Task 1.1\n",
    "\n",
    "Some of the fields in the data are not very amenable to serve as input to traditional machine learning algorithms. Namely, we have some fields for which there are a varying number of values (e.g. papers with 3 authors will have 3 values in the `author_citations` field, papers with 5 authors will have 5).\n",
    "\n",
    "\n",
    "Your first task is to perform some feature engineering and derive unique values for each paper which you will be able to use in your ML model. \n",
    "More specifically, you must:\n",
    "\n",
    "1. Create 3 new fields in the dataframe corresponding to the median value of the number of citations per author, the number of publications per author, and the h-index per author. So for instance, for the row `authors_publications`, you will create an additional column, e.g. `authors_publications_median`, containing the median number of publications per author in each paper.\n",
    "2. Create another field entitled `reputation` capturing how famous the last author of the paper is. Notice that the last author of the paper is usually the most senior person involved in the project. This field should equal $\\log_{10}\\Big(\\frac{\\#citations}{\\#publications} + 1\\Big)$. Notice that each author in the dataset has at least 1 publication, so you don't risk dividing by 0.\n",
    "3. Create two fields called `has_top_company` and `has_top_institution`. The field `has_top_company` equals 1 if the article contains an author in the following list of companies `[\"Facebook\", \"Google\", \"Microsoft\", \"Deepmind\"]`, and 0 otherwise. The field `has_top_institution` equals 1 if the article contains an author in the top 10 institutions according to CSRankings.\n",
    "4. **Discuss:** How did you handle -1 values in item 1.1.1? Justify your approach.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "DATA_FOLDER = 'data/'\n",
    "DF = DATA_FOLDER + \"dataset_final.csv\"\n",
    "PROPRENSITY = DATA_FOLDER + 'propensity_scores.csv.gz'\n",
    "df = pd.read_csv(DF, delimiter = \",\",header = 0)\n",
    "propensity_df=pd.read_csv(PROPRENSITY,compression='gzip',sep=',',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings</th>\n",
       "      <th>decisions</th>\n",
       "      <th>institution</th>\n",
       "      <th>csranking</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors_citations</th>\n",
       "      <th>authors_publications</th>\n",
       "      <th>authors_hindex</th>\n",
       "      <th>arxiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>Certifying Some Distributional Robustness with...</td>\n",
       "      <td>Aman Sinha;Hongseok Namkoong;John Duchi</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Stanford University;Stanford University;Stanfo...</td>\n",
       "      <td>4;4;4</td>\n",
       "      <td>4</td>\n",
       "      <td>655;904;12908</td>\n",
       "      <td>42;19;162</td>\n",
       "      <td>8;10;42</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>Parametric Information Bottleneck to Optimize ...</td>\n",
       "      <td>Thanh T. Nguyen;Jaesik Choi</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Ulsan National Institute of Science and Techno...</td>\n",
       "      <td>468;468</td>\n",
       "      <td>8</td>\n",
       "      <td>1052;727</td>\n",
       "      <td>86;88</td>\n",
       "      <td>16;15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                              paper  \\\n",
       "0  2018  Certifying Some Distributional Robustness with...   \n",
       "1  2018  Parametric Information Bottleneck to Optimize ...   \n",
       "\n",
       "                                   authors   ratings decisions  \\\n",
       "0  Aman Sinha;Hongseok Namkoong;John Duchi  9.000000    Accept   \n",
       "1              Thanh T. Nguyen;Jaesik Choi  4.666667    Reject   \n",
       "\n",
       "                                         institution csranking categories  \\\n",
       "0  Stanford University;Stanford University;Stanfo...     4;4;4          4   \n",
       "1  Ulsan National Institute of Science and Techno...   468;468          8   \n",
       "\n",
       "  authors_citations authors_publications authors_hindex  arxiv  \n",
       "0     655;904;12908            42;19;162        8;10;42   True  \n",
       "1          1052;727                86;88          16;15  False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['authors_citations_median'] = df['authors_citations'].apply(lambda x : np.median(np.fromstring(x,dtype=int, sep=\";\")))\n",
    "df['authors_publications_median'] = df['authors_publications'].apply(lambda x : np.median(np.fromstring(x,dtype=int, sep=\";\")))\n",
    "df['authors_hindex_median'] = df['authors_hindex'].apply(lambda x : np.median(np.fromstring(x,dtype=int, sep=\";\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Facebook|Google|Microsoft|Deepmind'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP_COMPANY = '|'.join([\"Facebook\", \"Google\", \"Microsoft\", \"Deepmind\"])\n",
    "TOP_COMPANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reputation'] = np.log10(( df['authors_citations'].apply(lambda x : (np.fromstring(x,dtype=int, sep=\";\")).take(-1))\n",
    "                          / df['authors_publications'].apply(lambda x : (np.fromstring(x,dtype=int, sep=\";\")).take(-1))\n",
    "                          )+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for task 1.4\n",
    "df['crazy'] = - df['ratings'] \n",
    "df.loc[df['ratings'] < 4.96,'crazy'] = 9 - df['ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_top_company'] = df['institution'].apply(lambda x : 1 if (x.__contains__(\"Facebook\")\n",
    "                                                |x.__contains__(\"Google\") \n",
    "                                                |x.__contains__(\"Microsoft\")\n",
    "                                                |x.__contains__(\"Deepmind\"))\n",
    "                                                 else 0)\n",
    "\n",
    "\n",
    "df['csranking'] = df['csranking'].str.split(';').apply(lambda x: list(map(int,x)))\n",
    "\n",
    "def is_inbetween(x, min_ = 0, max_ = 10):\n",
    "    'Return true if values is inbetween 0 and 10, otherwise false'\n",
    "    \n",
    "    if (x >= min_) & (x <= 10):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df['has_top_institution'] = df['csranking'].apply(lambda x: any([is_inbetween(i) for i in x])).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings</th>\n",
       "      <th>decisions</th>\n",
       "      <th>institution</th>\n",
       "      <th>csranking</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors_citations</th>\n",
       "      <th>authors_publications</th>\n",
       "      <th>authors_hindex</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "      <th>crazy</th>\n",
       "      <th>has_top_company</th>\n",
       "      <th>has_top_institution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>Certifying Some Distributional Robustness with...</td>\n",
       "      <td>Aman Sinha;Hongseok Namkoong;John Duchi</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Stanford University;Stanford University;Stanfo...</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>4</td>\n",
       "      <td>655;904;12908</td>\n",
       "      <td>42;19;162</td>\n",
       "      <td>8;10;42</td>\n",
       "      <td>True</td>\n",
       "      <td>904.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.906761</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>Towards Neural Phrase-based Machine Translation</td>\n",
       "      <td>Po-Sen Huang;Chong Wang;Sitao Huang;Dengyong Z...</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Microsoft;Google;University of Illinois, Urban...</td>\n",
       "      <td>[-1, -1, 3, -1, -1]</td>\n",
       "      <td>3;2</td>\n",
       "      <td>1718;17889;161;8800;20766</td>\n",
       "      <td>59;1045;17;78;409</td>\n",
       "      <td>17;54;7;33;63</td>\n",
       "      <td>True</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.714100</td>\n",
       "      <td>-6.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>Countering Adversarial Images using Input Tran...</td>\n",
       "      <td>Chuan Guo;Mayank Rana;Moustapha Cisse;Laurens ...</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Cornell University;Facebook;Facebook;Facebook</td>\n",
       "      <td>[7, -1, -1, -1]</td>\n",
       "      <td>4</td>\n",
       "      <td>1313;392;2917;17805</td>\n",
       "      <td>23;5;48;93</td>\n",
       "      <td>8;2;19;32</td>\n",
       "      <td>True</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.284322</td>\n",
       "      <td>-6.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>Minimax Curriculum Learning: Machine Teaching ...</td>\n",
       "      <td>Tianyi Zhou;Jeff Bilmes</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>Accept</td>\n",
       "      <td>University of Washington;University of Washing...</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>1444;13443</td>\n",
       "      <td>80;348</td>\n",
       "      <td>14;53</td>\n",
       "      <td>False</td>\n",
       "      <td>7443.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>1.598017</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018</td>\n",
       "      <td>Go for a Walk and Arrive at the Answer: Reason...</td>\n",
       "      <td>Rajarshi Das;Shehzaad Dhuliawala;Manzil Zaheer...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Accept</td>\n",
       "      <td>University of Massachusetts, Amherst;Universit...</td>\n",
       "      <td>[30, 30, 1, 30, 21, 30, 1, 30]</td>\n",
       "      <td>10</td>\n",
       "      <td>4903;183;1602;1764;335;1537;68208;45557</td>\n",
       "      <td>164;14;63;25;15;75;404;434</td>\n",
       "      <td>33;3;17;10;5;21;99;96</td>\n",
       "      <td>False</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.025183</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018</td>\n",
       "      <td>Simulating Action Dynamics with Neural Process...</td>\n",
       "      <td>Antoine Bosselut;Omer Levy;Ari Holtzman;Corin ...</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>Accept</td>\n",
       "      <td>University of Washington;University of Washing...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>397;7449;600;139;39994;7812</td>\n",
       "      <td>20;58;18;3;374;139</td>\n",
       "      <td>8;30;10;2;97;43</td>\n",
       "      <td>False</td>\n",
       "      <td>4024.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.757407</td>\n",
       "      <td>-7.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>QANet: Combining Local Convolution with Global...</td>\n",
       "      <td>Adams Wei Yu;David Dohan;Minh-Thang Luong;Rui ...</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Carnegie Mellon University;Google;Google;Googl...</td>\n",
       "      <td>[1, -1, -1, -1, -1, -1, -1]</td>\n",
       "      <td>3</td>\n",
       "      <td>815;1093;3101;8364;33496;8079;48714</td>\n",
       "      <td>28;11;33;608;46;126;193</td>\n",
       "      <td>13;4;20;39;12;31;81</td>\n",
       "      <td>False</td>\n",
       "      <td>8079.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.403814</td>\n",
       "      <td>-6.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>Zero-Shot Visual Imitation</td>\n",
       "      <td>Deepak Pathak;Parsa Mahmoudieh;Guanghao Luo;Pu...</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>Accept</td>\n",
       "      <td>University of California Berkeley;University o...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>6</td>\n",
       "      <td>4211;191;111;3015;369;124;27413;70210;37176;90665</td>\n",
       "      <td>40;8;1;52;34;2;26;429;193;559</td>\n",
       "      <td>14;4;1;16;8;2;14;115;77;112</td>\n",
       "      <td>False</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.212697</td>\n",
       "      <td>-7.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>Spatially Transformed Adversarial Examples</td>\n",
       "      <td>Chaowei Xiao;Jun-Yan Zhu;Bo Li;Warren He;Mingy...</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>Accept</td>\n",
       "      <td>University of Michigan;NAVER;University of Cal...</td>\n",
       "      <td>[8, -1, 5, 5, 8, 5]</td>\n",
       "      <td>4</td>\n",
       "      <td>1318;15358;2365;1204;12506;43319</td>\n",
       "      <td>30;50;80;22;264;396</td>\n",
       "      <td>12;27;23;14;38;100</td>\n",
       "      <td>False</td>\n",
       "      <td>7435.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.042935</td>\n",
       "      <td>-7.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year                                              paper  \\\n",
       "0   2018  Certifying Some Distributional Robustness with...   \n",
       "2   2018    Towards Neural Phrase-based Machine Translation   \n",
       "5   2018  Countering Adversarial Images using Input Tran...   \n",
       "8   2018  Minimax Curriculum Learning: Machine Teaching ...   \n",
       "13  2018  Go for a Walk and Arrive at the Answer: Reason...   \n",
       "16  2018  Simulating Action Dynamics with Neural Process...   \n",
       "18  2018  QANet: Combining Local Convolution with Global...   \n",
       "22  2018                         Zero-Shot Visual Imitation   \n",
       "26  2018         Spatially Transformed Adversarial Examples   \n",
       "\n",
       "                                              authors   ratings decisions  \\\n",
       "0             Aman Sinha;Hongseok Namkoong;John Duchi  9.000000    Accept   \n",
       "2   Po-Sen Huang;Chong Wang;Sitao Huang;Dengyong Z...  6.666667    Accept   \n",
       "5   Chuan Guo;Mayank Rana;Moustapha Cisse;Laurens ...  6.333333    Accept   \n",
       "8                             Tianyi Zhou;Jeff Bilmes  5.666667    Accept   \n",
       "13  Rajarshi Das;Shehzaad Dhuliawala;Manzil Zaheer...  6.000000    Accept   \n",
       "16  Antoine Bosselut;Omer Levy;Ari Holtzman;Corin ...  7.666667    Accept   \n",
       "18  Adams Wei Yu;David Dohan;Minh-Thang Luong;Rui ...  6.333333    Accept   \n",
       "22  Deepak Pathak;Parsa Mahmoudieh;Guanghao Luo;Pu...  7.666667    Accept   \n",
       "26  Chaowei Xiao;Jun-Yan Zhu;Bo Li;Warren He;Mingy...  7.666667    Accept   \n",
       "\n",
       "                                          institution  \\\n",
       "0   Stanford University;Stanford University;Stanfo...   \n",
       "2   Microsoft;Google;University of Illinois, Urban...   \n",
       "5       Cornell University;Facebook;Facebook;Facebook   \n",
       "8   University of Washington;University of Washing...   \n",
       "13  University of Massachusetts, Amherst;Universit...   \n",
       "16  University of Washington;University of Washing...   \n",
       "18  Carnegie Mellon University;Google;Google;Googl...   \n",
       "22  University of California Berkeley;University o...   \n",
       "26  University of Michigan;NAVER;University of Cal...   \n",
       "\n",
       "                         csranking categories  \\\n",
       "0                        [4, 4, 4]          4   \n",
       "2              [-1, -1, 3, -1, -1]        3;2   \n",
       "5                  [7, -1, -1, -1]          4   \n",
       "8                           [6, 6]          0   \n",
       "13  [30, 30, 1, 30, 21, 30, 1, 30]         10   \n",
       "16              [6, 6, 6, 6, 6, 6]          0   \n",
       "18     [1, -1, -1, -1, -1, -1, -1]          3   \n",
       "22  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]          6   \n",
       "26             [8, -1, 5, 5, 8, 5]          4   \n",
       "\n",
       "                                    authors_citations  \\\n",
       "0                                       655;904;12908   \n",
       "2                           1718;17889;161;8800;20766   \n",
       "5                                 1313;392;2917;17805   \n",
       "8                                          1444;13443   \n",
       "13            4903;183;1602;1764;335;1537;68208;45557   \n",
       "16                        397;7449;600;139;39994;7812   \n",
       "18                815;1093;3101;8364;33496;8079;48714   \n",
       "22  4211;191;111;3015;369;124;27413;70210;37176;90665   \n",
       "26                   1318;15358;2365;1204;12506;43319   \n",
       "\n",
       "             authors_publications               authors_hindex  arxiv  \\\n",
       "0                       42;19;162                      8;10;42   True   \n",
       "2               59;1045;17;78;409                17;54;7;33;63   True   \n",
       "5                      23;5;48;93                    8;2;19;32   True   \n",
       "8                          80;348                        14;53  False   \n",
       "13     164;14;63;25;15;75;404;434        33;3;17;10;5;21;99;96  False   \n",
       "16             20;58;18;3;374;139              8;30;10;2;97;43  False   \n",
       "18        28;11;33;608;46;126;193          13;4;20;39;12;31;81  False   \n",
       "22  40;8;1;52;34;2;26;429;193;559  14;4;1;16;8;2;14;115;77;112  False   \n",
       "26            30;50;80;22;264;396           12;27;23;14;38;100  False   \n",
       "\n",
       "    authors_citations_median  authors_publications_median  \\\n",
       "0                      904.0                         42.0   \n",
       "2                     8800.0                         78.0   \n",
       "5                     2115.0                         35.5   \n",
       "8                     7443.5                        214.0   \n",
       "13                    1683.0                         69.0   \n",
       "16                    4024.5                         39.0   \n",
       "18                    8079.0                         46.0   \n",
       "22                    3613.0                         37.0   \n",
       "26                    7435.5                         65.0   \n",
       "\n",
       "    authors_hindex_median  reputation     crazy  has_top_company  \\\n",
       "0                    10.0    1.906761 -9.000000                0   \n",
       "2                    33.0    1.714100 -6.666667                1   \n",
       "5                    13.5    2.284322 -6.333333                1   \n",
       "8                    33.5    1.598017 -5.666667                0   \n",
       "13                   19.0    2.025183 -6.000000                0   \n",
       "16                   20.0    1.757407 -7.666667                0   \n",
       "18                   20.0    2.403814 -6.333333                1   \n",
       "22                   14.0    2.212697 -7.666667                0   \n",
       "26                   25.0    2.042935 -7.666667                0   \n",
       "\n",
       "    has_top_institution  \n",
       "0                     1  \n",
       "2                     1  \n",
       "5                     1  \n",
       "8                     1  \n",
       "13                    1  \n",
       "16                    1  \n",
       "18                    1  \n",
       "22                    1  \n",
       "26                    1  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['has_top_institution']==1].head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2\n",
    "\n",
    "Now that you have cleaned up your data, your next task is to divide your data into a training set and a testing set. You should do this in two ways:\n",
    "\n",
    "1. First, do it randomly. Split the data into a training set (70%) and a testing set (30%). We refer to these as \"random split\" in the subsequent tasks.\n",
    "2. Second, do it longitudinally. Use the data from 2018 and 2019 for the training set, and the data from 2020 as the testing set. We refer to these as \"longitudinal split\" in the subsequent tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings</th>\n",
       "      <th>decisions</th>\n",
       "      <th>institution</th>\n",
       "      <th>csranking</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors_citations</th>\n",
       "      <th>authors_publications</th>\n",
       "      <th>authors_hindex</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "      <th>crazy</th>\n",
       "      <th>has_top_company</th>\n",
       "      <th>has_top_institution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>2020</td>\n",
       "      <td>CAT: Compression-Aware Training for bandwidth ...</td>\n",
       "      <td>Chaim Baskin;Brian Chmiel;Evgenii Zheltonozhsk...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Technion;Intel;Technion;Intel;Technion;Technion</td>\n",
       "      <td>26;-1;26;-1;26;26</td>\n",
       "      <td>0</td>\n",
       "      <td>92;9;78;532;136;1693</td>\n",
       "      <td>14;8;10;31;16;138</td>\n",
       "      <td>5;2;4;11;6;23</td>\n",
       "      <td>True</td>\n",
       "      <td>114.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.122809</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2019</td>\n",
       "      <td>Learning to Remember More with Less Memorization</td>\n",
       "      <td>Hung Le;Truyen Tran;Svetha Venkatesh</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Deakin University;Deakin University;Deakin Uni...</td>\n",
       "      <td>478;478;478</td>\n",
       "      <td>1</td>\n",
       "      <td>730;1857;8523</td>\n",
       "      <td>49;133;561</td>\n",
       "      <td>10;24;43</td>\n",
       "      <td>False</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.209314</td>\n",
       "      <td>-7.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>2019</td>\n",
       "      <td>Deterministic PAC-Bayesian generalization boun...</td>\n",
       "      <td>Vaishnavh Nagarajan;Zico Kolter</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Carnegie Mellon University;Carnegie Mellon Uni...</td>\n",
       "      <td>1;1</td>\n",
       "      <td>11;1;8</td>\n",
       "      <td>303;7460</td>\n",
       "      <td>22;104</td>\n",
       "      <td>8;34</td>\n",
       "      <td>False</td>\n",
       "      <td>3881.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.861718</td>\n",
       "      <td>-6.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2019</td>\n",
       "      <td>SNAS: stochastic neural architecture search</td>\n",
       "      <td>Sirui Xie;Hehui Zheng;Chunxiao Liu;Liang Lin</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>Accept</td>\n",
       "      <td>SenseTime Group Limited;SenseTime Group Limite...</td>\n",
       "      <td>-1;-1;-1;478</td>\n",
       "      <td>1</td>\n",
       "      <td>217;354;462;8625</td>\n",
       "      <td>7;9;48;294</td>\n",
       "      <td>2;4;10;49</td>\n",
       "      <td>False</td>\n",
       "      <td>408.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.481969</td>\n",
       "      <td>-6.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>2020</td>\n",
       "      <td>SpikeGrad: An ANN-equivalent Computation Model...</td>\n",
       "      <td>Johannes C. Thiele;Olivier Bichler;Antoine Dupret</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Accept</td>\n",
       "      <td>CEA;CEA;CEA</td>\n",
       "      <td>233;233;233</td>\n",
       "      <td>0</td>\n",
       "      <td>39;2057;560</td>\n",
       "      <td>8;69;138</td>\n",
       "      <td>3;22;12</td>\n",
       "      <td>True</td>\n",
       "      <td>560.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.703976</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>2020</td>\n",
       "      <td>A Boolean Task Algebra for Reinforcement Learning</td>\n",
       "      <td>Geraud Nangue Tasse;Steven James;Benjamin Rosman</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>Reject</td>\n",
       "      <td>University of the Witwatersrand;University of ...</td>\n",
       "      <td>481;481;233</td>\n",
       "      <td>1</td>\n",
       "      <td>1;206;454</td>\n",
       "      <td>1;62;78</td>\n",
       "      <td>1;6;12</td>\n",
       "      <td>False</td>\n",
       "      <td>206.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.833817</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2018</td>\n",
       "      <td>Learning Independent Features with Adversarial...</td>\n",
       "      <td>Philemon Brakel;Yoshua Bengio</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Google;University of Montreal</td>\n",
       "      <td>-1;124</td>\n",
       "      <td>4</td>\n",
       "      <td>1721;201719</td>\n",
       "      <td>21;807</td>\n",
       "      <td>16;147</td>\n",
       "      <td>True</td>\n",
       "      <td>101720.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>2.399607</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>2020</td>\n",
       "      <td>Zero-shot task adaptation by homoiconic meta-m...</td>\n",
       "      <td>Andrew K. Lampinen;James L. McClelland</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Stanford University;Stanford University</td>\n",
       "      <td>4;4</td>\n",
       "      <td>6</td>\n",
       "      <td>91;43165</td>\n",
       "      <td>22;424</td>\n",
       "      <td>5;82</td>\n",
       "      <td>True</td>\n",
       "      <td>21628.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>2020</td>\n",
       "      <td>Improved Training Techniques for Online Neural...</td>\n",
       "      <td>Maha Elbayad;Laurent Besacier;Jakob Verbeek</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Reject</td>\n",
       "      <td>INRIA;University of Grenoble-Alpes;INRIA</td>\n",
       "      <td>-1;481;-1</td>\n",
       "      <td>3</td>\n",
       "      <td>60;143;8789</td>\n",
       "      <td>6;38;103</td>\n",
       "      <td>3;6;38</td>\n",
       "      <td>False</td>\n",
       "      <td>143.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.936162</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2018</td>\n",
       "      <td>Learning Gaussian Policies from Smoothed Actio...</td>\n",
       "      <td>Ofir Nachum;Mohammad Norouzi;George Tucker;Dal...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Google;Google;Google;Google</td>\n",
       "      <td>-1;-1;-1;-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1038;7796;2809;6071</td>\n",
       "      <td>41;125;75;247</td>\n",
       "      <td>15;30;21;41</td>\n",
       "      <td>False</td>\n",
       "      <td>4440.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>1.407883</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2979 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                                              paper  \\\n",
       "3472  2020  CAT: Compression-Aware Training for bandwidth ...   \n",
       "1240  2019   Learning to Remember More with Less Memorization   \n",
       "1024  2019  Deterministic PAC-Bayesian generalization boun...   \n",
       "1257  2019        SNAS: stochastic neural architecture search   \n",
       "2581  2020  SpikeGrad: An ANN-equivalent Computation Model...   \n",
       "...    ...                                                ...   \n",
       "3664  2020  A Boolean Task Algebra for Reinforcement Learning   \n",
       "593   2018  Learning Independent Features with Adversarial...   \n",
       "4081  2020  Zero-shot task adaptation by homoiconic meta-m...   \n",
       "3481  2020  Improved Training Techniques for Online Neural...   \n",
       "579   2018  Learning Gaussian Policies from Smoothed Actio...   \n",
       "\n",
       "                                                authors   ratings decisions  \\\n",
       "3472  Chaim Baskin;Brian Chmiel;Evgenii Zheltonozhsk...  6.000000    Reject   \n",
       "1240               Hung Le;Truyen Tran;Svetha Venkatesh  7.333333    Accept   \n",
       "1024                    Vaishnavh Nagarajan;Zico Kolter  6.750000    Accept   \n",
       "1257       Sirui Xie;Hehui Zheng;Chunxiao Liu;Liang Lin  6.666667    Accept   \n",
       "2581  Johannes C. Thiele;Olivier Bichler;Antoine Dupret  6.000000    Accept   \n",
       "...                                                 ...       ...       ...   \n",
       "3664   Geraud Nangue Tasse;Steven James;Benjamin Rosman  4.666667    Reject   \n",
       "593                       Philemon Brakel;Yoshua Bengio  4.666667    Reject   \n",
       "4081             Andrew K. Lampinen;James L. McClelland  3.000000    Reject   \n",
       "3481        Maha Elbayad;Laurent Besacier;Jakob Verbeek  4.000000    Reject   \n",
       "579   Ofir Nachum;Mohammad Norouzi;George Tucker;Dal...  5.666667    Reject   \n",
       "\n",
       "                                            institution          csranking  \\\n",
       "3472    Technion;Intel;Technion;Intel;Technion;Technion  26;-1;26;-1;26;26   \n",
       "1240  Deakin University;Deakin University;Deakin Uni...        478;478;478   \n",
       "1024  Carnegie Mellon University;Carnegie Mellon Uni...                1;1   \n",
       "1257  SenseTime Group Limited;SenseTime Group Limite...       -1;-1;-1;478   \n",
       "2581                                        CEA;CEA;CEA        233;233;233   \n",
       "...                                                 ...                ...   \n",
       "3664  University of the Witwatersrand;University of ...        481;481;233   \n",
       "593                       Google;University of Montreal             -1;124   \n",
       "4081            Stanford University;Stanford University                4;4   \n",
       "3481           INRIA;University of Grenoble-Alpes;INRIA          -1;481;-1   \n",
       "579                         Google;Google;Google;Google        -1;-1;-1;-1   \n",
       "\n",
       "     categories     authors_citations authors_publications authors_hindex  \\\n",
       "3472          0  92;9;78;532;136;1693    14;8;10;31;16;138  5;2;4;11;6;23   \n",
       "1240          1         730;1857;8523           49;133;561       10;24;43   \n",
       "1024     11;1;8              303;7460               22;104           8;34   \n",
       "1257          1      217;354;462;8625           7;9;48;294      2;4;10;49   \n",
       "2581          0           39;2057;560             8;69;138        3;22;12   \n",
       "...         ...                   ...                  ...            ...   \n",
       "3664          1             1;206;454              1;62;78         1;6;12   \n",
       "593           4           1721;201719               21;807         16;147   \n",
       "4081          6              91;43165               22;424           5;82   \n",
       "3481          3           60;143;8789             6;38;103         3;6;38   \n",
       "579           0   1038;7796;2809;6071        41;125;75;247    15;30;21;41   \n",
       "\n",
       "      arxiv  authors_citations_median  authors_publications_median  \\\n",
       "3472   True                     114.0                         15.0   \n",
       "1240  False                    1857.0                        133.0   \n",
       "1024  False                    3881.5                         63.0   \n",
       "1257  False                     408.0                         28.5   \n",
       "2581   True                     560.0                         69.0   \n",
       "...     ...                       ...                          ...   \n",
       "3664  False                     206.0                         62.0   \n",
       "593    True                  101720.0                        414.0   \n",
       "4081   True                   21628.0                        223.0   \n",
       "3481  False                     143.0                         38.0   \n",
       "579   False                    4440.0                        100.0   \n",
       "\n",
       "      authors_hindex_median  reputation     crazy  has_top_company  \\\n",
       "3472                    5.5    1.122809 -6.000000                0   \n",
       "1240                   24.0    1.209314 -7.333333                0   \n",
       "1024                   21.0    1.861718 -6.750000                0   \n",
       "1257                    7.0    1.481969 -6.666667                0   \n",
       "2581                   12.0    0.703976 -6.000000                0   \n",
       "...                     ...         ...       ...              ...   \n",
       "3664                    6.0    0.833817  4.333333                0   \n",
       "593                    81.5    2.399607  4.333333                1   \n",
       "4081                   43.5    2.012011  6.000000                0   \n",
       "3481                    6.0    1.936162  5.000000                0   \n",
       "579                    25.5    1.407883 -5.666667                1   \n",
       "\n",
       "      has_top_institution  \n",
       "3472                    1  \n",
       "1240                    1  \n",
       "1024                    1  \n",
       "1257                    1  \n",
       "2581                    1  \n",
       "...                   ...  \n",
       "3664                    1  \n",
       "593                     1  \n",
       "4081                    1  \n",
       "3481                    1  \n",
       "579                     0  \n",
       "\n",
       "[2979 rows x 19 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train= df.sample(frac=0.7) # aussi possible de split les datas comme ça !\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings</th>\n",
       "      <th>decisions</th>\n",
       "      <th>institution</th>\n",
       "      <th>csranking</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors_citations</th>\n",
       "      <th>authors_publications</th>\n",
       "      <th>authors_hindex</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "      <th>crazy</th>\n",
       "      <th>has_top_company</th>\n",
       "      <th>has_top_institution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>Certifying Some Distributional Robustness with...</td>\n",
       "      <td>Aman Sinha;Hongseok Namkoong;John Duchi</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Stanford University;Stanford University;Stanfo...</td>\n",
       "      <td>4;4;4</td>\n",
       "      <td>4</td>\n",
       "      <td>655;904;12908</td>\n",
       "      <td>42;19;162</td>\n",
       "      <td>8;10;42</td>\n",
       "      <td>True</td>\n",
       "      <td>904.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.906761</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>Parametric Information Bottleneck to Optimize ...</td>\n",
       "      <td>Thanh T. Nguyen;Jaesik Choi</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Ulsan National Institute of Science and Techno...</td>\n",
       "      <td>468;468</td>\n",
       "      <td>8</td>\n",
       "      <td>1052;727</td>\n",
       "      <td>86;88</td>\n",
       "      <td>16;15</td>\n",
       "      <td>False</td>\n",
       "      <td>889.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.966675</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>Towards Neural Phrase-based Machine Translation</td>\n",
       "      <td>Po-Sen Huang;Chong Wang;Sitao Huang;Dengyong Z...</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Microsoft;Google;University of Illinois, Urban...</td>\n",
       "      <td>-1;-1;3;-1;-1</td>\n",
       "      <td>3;2</td>\n",
       "      <td>1718;17889;161;8800;20766</td>\n",
       "      <td>59;1045;17;78;409</td>\n",
       "      <td>17;54;7;33;63</td>\n",
       "      <td>True</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.714100</td>\n",
       "      <td>-6.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>Interactive Grounded Language Acquisition and ...</td>\n",
       "      <td>Haonan Yu;Haichao Zhang;Wei Xu</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Baidu;Baidu;Baidu</td>\n",
       "      <td>-1;-1;-1</td>\n",
       "      <td>6;8</td>\n",
       "      <td>890;1382;9553</td>\n",
       "      <td>37;63;557</td>\n",
       "      <td>12;20;44</td>\n",
       "      <td>False</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.258896</td>\n",
       "      <td>-6.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>A Boo(n) for Evaluating Architecture Performance</td>\n",
       "      <td>Ondrej Bajgar;Rudolf Kadlec;and Jan Kleindienst</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>Reject</td>\n",
       "      <td>;International Business Machines;International...</td>\n",
       "      <td>-1;-1;-1</td>\n",
       "      <td>0</td>\n",
       "      <td>366;678;658</td>\n",
       "      <td>10;40;76</td>\n",
       "      <td>5;11;9</td>\n",
       "      <td>False</td>\n",
       "      <td>658.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.984882</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>2020</td>\n",
       "      <td>A Finite-Time Analysis of  Q-Learning with Neu...</td>\n",
       "      <td>Pan Xu;Quanquan Gu</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Reject</td>\n",
       "      <td>University of California, Los Angeles;Universi...</td>\n",
       "      <td>20;20</td>\n",
       "      <td>1;9</td>\n",
       "      <td>295;3895</td>\n",
       "      <td>31;174</td>\n",
       "      <td>10;34</td>\n",
       "      <td>False</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>102.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.368938</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCELMo: Source Code Embeddings from Language M...</td>\n",
       "      <td>Rafael - Michael Karampatsis;Charles Sutton</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>Reject</td>\n",
       "      <td>University of Edinburgh;Google</td>\n",
       "      <td>33;-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0;50</td>\n",
       "      <td>1;18</td>\n",
       "      <td>0;3</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>2020</td>\n",
       "      <td>GraphMix: Regularized Training of Graph Neural...</td>\n",
       "      <td>Vikas Verma;Meng Qu;Alex Lamb;Yoshua Bengio;Ju...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Reject</td>\n",
       "      <td>;University of Montreal;University of Montreal...</td>\n",
       "      <td>-1;128;128;128;143;128</td>\n",
       "      <td>10</td>\n",
       "      <td>202;504;2136;208566;3645;346</td>\n",
       "      <td>25;40;22;807;127;94</td>\n",
       "      <td>4;5;8;147;24;8</td>\n",
       "      <td>True</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.670325</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>2020</td>\n",
       "      <td>Neural networks with motivation</td>\n",
       "      <td>Sergey A. Shuvaev;Ngoc B. Tran;Marcus Stephens...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Cold Spring Harbor Laboratory;Cold Spring Harb...</td>\n",
       "      <td>-1;-1;-1;-1;-1</td>\n",
       "      <td>5</td>\n",
       "      <td>16;94;563;997;1816</td>\n",
       "      <td>8;12;14;67;83</td>\n",
       "      <td>3;3;9;9;16</td>\n",
       "      <td>True</td>\n",
       "      <td>563.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.359447</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>2020</td>\n",
       "      <td>Measuring causal influence with back-to-back r...</td>\n",
       "      <td>Jean-Remi King;Francois Charton;Maxime Oquab;D...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Facebook;Facebook;Facebook;Facebook</td>\n",
       "      <td>-1;-1;-1;-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1273;1;2971;2483</td>\n",
       "      <td>45;14;20;46</td>\n",
       "      <td>16;1;7;19</td>\n",
       "      <td>False</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.740191</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4256 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                                              paper  \\\n",
       "0     2018  Certifying Some Distributional Robustness with...   \n",
       "1     2018  Parametric Information Bottleneck to Optimize ...   \n",
       "2     2018    Towards Neural Phrase-based Machine Translation   \n",
       "3     2018  Interactive Grounded Language Acquisition and ...   \n",
       "4     2018   A Boo(n) for Evaluating Architecture Performance   \n",
       "...    ...                                                ...   \n",
       "4251  2020  A Finite-Time Analysis of  Q-Learning with Neu...   \n",
       "4252  2020  SCELMo: Source Code Embeddings from Language M...   \n",
       "4253  2020  GraphMix: Regularized Training of Graph Neural...   \n",
       "4254  2020                    Neural networks with motivation   \n",
       "4255  2020  Measuring causal influence with back-to-back r...   \n",
       "\n",
       "                                                authors   ratings decisions  \\\n",
       "0               Aman Sinha;Hongseok Namkoong;John Duchi  9.000000    Accept   \n",
       "1                           Thanh T. Nguyen;Jaesik Choi  4.666667    Reject   \n",
       "2     Po-Sen Huang;Chong Wang;Sitao Huang;Dengyong Z...  6.666667    Accept   \n",
       "3                        Haonan Yu;Haichao Zhang;Wei Xu  6.333333    Accept   \n",
       "4       Ondrej Bajgar;Rudolf Kadlec;and Jan Kleindienst  4.666667    Reject   \n",
       "...                                                 ...       ...       ...   \n",
       "4251                                 Pan Xu;Quanquan Gu  5.000000    Reject   \n",
       "4252        Rafael - Michael Karampatsis;Charles Sutton  4.666667    Reject   \n",
       "4253  Vikas Verma;Meng Qu;Alex Lamb;Yoshua Bengio;Ju...  4.000000    Reject   \n",
       "4254  Sergey A. Shuvaev;Ngoc B. Tran;Marcus Stephens...  2.333333    Reject   \n",
       "4255  Jean-Remi King;Francois Charton;Maxime Oquab;D...  4.000000    Reject   \n",
       "\n",
       "                                            institution  \\\n",
       "0     Stanford University;Stanford University;Stanfo...   \n",
       "1     Ulsan National Institute of Science and Techno...   \n",
       "2     Microsoft;Google;University of Illinois, Urban...   \n",
       "3                                     Baidu;Baidu;Baidu   \n",
       "4     ;International Business Machines;International...   \n",
       "...                                                 ...   \n",
       "4251  University of California, Los Angeles;Universi...   \n",
       "4252                     University of Edinburgh;Google   \n",
       "4253  ;University of Montreal;University of Montreal...   \n",
       "4254  Cold Spring Harbor Laboratory;Cold Spring Harb...   \n",
       "4255                Facebook;Facebook;Facebook;Facebook   \n",
       "\n",
       "                   csranking categories             authors_citations  \\\n",
       "0                      4;4;4          4                 655;904;12908   \n",
       "1                    468;468          8                      1052;727   \n",
       "2              -1;-1;3;-1;-1        3;2     1718;17889;161;8800;20766   \n",
       "3                   -1;-1;-1        6;8                 890;1382;9553   \n",
       "4                   -1;-1;-1          0                   366;678;658   \n",
       "...                      ...        ...                           ...   \n",
       "4251                   20;20        1;9                      295;3895   \n",
       "4252                   33;-1          3                          0;50   \n",
       "4253  -1;128;128;128;143;128         10  202;504;2136;208566;3645;346   \n",
       "4254          -1;-1;-1;-1;-1          5            16;94;563;997;1816   \n",
       "4255             -1;-1;-1;-1          0              1273;1;2971;2483   \n",
       "\n",
       "     authors_publications  authors_hindex  arxiv  authors_citations_median  \\\n",
       "0               42;19;162         8;10;42   True                     904.0   \n",
       "1                   86;88           16;15  False                     889.5   \n",
       "2       59;1045;17;78;409   17;54;7;33;63   True                    8800.0   \n",
       "3               37;63;557        12;20;44  False                    1382.0   \n",
       "4                10;40;76          5;11;9  False                     658.0   \n",
       "...                   ...             ...    ...                       ...   \n",
       "4251               31;174           10;34  False                    2095.0   \n",
       "4252                 1;18             0;3  False                      25.0   \n",
       "4253  25;40;22;807;127;94  4;5;8;147;24;8   True                    1320.0   \n",
       "4254        8;12;14;67;83      3;3;9;9;16   True                     563.0   \n",
       "4255          45;14;20;46       16;1;7;19  False                    1878.0   \n",
       "\n",
       "      authors_publications_median  authors_hindex_median  reputation  \\\n",
       "0                            42.0                   10.0    1.906761   \n",
       "1                            87.0                   15.5    0.966675   \n",
       "2                            78.0                   33.0    1.714100   \n",
       "3                            63.0                   20.0    1.258896   \n",
       "4                            40.0                    9.0    0.984882   \n",
       "...                           ...                    ...         ...   \n",
       "4251                        102.5                   22.0    1.368938   \n",
       "4252                          9.5                    1.5    0.577236   \n",
       "4253                         67.0                    8.0    0.670325   \n",
       "4254                         14.0                    9.0    1.359447   \n",
       "4255                         32.5                   11.5    1.740191   \n",
       "\n",
       "         crazy  has_top_company  has_top_institution  \n",
       "0    -9.000000                0                    1  \n",
       "1     4.333333                0                    1  \n",
       "2    -6.666667                1                    1  \n",
       "3    -6.333333                0                    0  \n",
       "4     4.333333                0                    0  \n",
       "...        ...              ...                  ...  \n",
       "4251 -5.000000                0                    1  \n",
       "4252  4.333333                1                    1  \n",
       "4253  5.000000                0                    1  \n",
       "4254  6.666667                0                    0  \n",
       "4255  5.000000                1                    0  \n",
       "\n",
       "[4256 rows x 19 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,y,test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = test_size, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3\n",
    "\n",
    "Build a Linear Regression model (use [sklearn](https://scikit-learn.org/stable/)) that predicts the score of a paper (which is in the variable ratings in the dataframe). Train it and test it using the split you previously defined. Your model should use as features:\n",
    "- Median values for the number of author citations, publications and h-indexes, as calculated in Task 1.1.1.\n",
    "\n",
    "- `reputation` of the last author, as calculated in Task 1.1.2.\n",
    "\n",
    "For the two scenarios above (random split and longitudinal split):\n",
    "\n",
    "1. Report the model $R^2$ in each case (for the testing set).\n",
    "2. **Discuss:** Hypothesize a reason why the results are different. Additionally, interpret the $R^2$ value for the longitudinal split. How can it be negative?\n",
    "3. **From now onwards (in this task and the following ones), consider only the random split.** For a given entry $X$ your model outputs a predicted score $Y'$. The difference between the real score $Y$ and the predicted score $Y'$ is called the \"residual\". Plot the distribution of your residuals for the test set. Using this distribution, estimate what is the probability that your prediction is off by more than 2-points? Provide bootstrapped confidence intervals for your answer.\n",
    "4. **Discuss:** Identify three additional features that are already computed in your dataframe and that could boost your model's predictive performance. You are not allowed to use the variable `decisions` as an input here. Before running any experiments, discuss why each of these features might add valuable information to your model.\n",
    "5. Report the $R^2$ (for the test set) for a newly trained model with these additional features. Please note that you do not need to improve the model performance to be successful in this task!\n",
    "\n",
    "**Hint**: [Metrics!](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>904.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.906761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>889.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.966675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8800.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1382.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.258896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.984882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>2095.0</td>\n",
       "      <td>102.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.368938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>25.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.577236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>1320.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.670325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>563.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.359447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>1878.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.740191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4256 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      authors_citations_median  authors_publications_median  \\\n",
       "0                        904.0                         42.0   \n",
       "1                        889.5                         87.0   \n",
       "2                       8800.0                         78.0   \n",
       "3                       1382.0                         63.0   \n",
       "4                        658.0                         40.0   \n",
       "...                        ...                          ...   \n",
       "4251                    2095.0                        102.5   \n",
       "4252                      25.0                          9.5   \n",
       "4253                    1320.0                         67.0   \n",
       "4254                     563.0                         14.0   \n",
       "4255                    1878.0                         32.5   \n",
       "\n",
       "      authors_hindex_median  reputation  \n",
       "0                      10.0    1.906761  \n",
       "1                      15.5    0.966675  \n",
       "2                      33.0    1.714100  \n",
       "3                      20.0    1.258896  \n",
       "4                       9.0    0.984882  \n",
       "...                     ...         ...  \n",
       "4251                   22.0    1.368938  \n",
       "4252                    1.5    0.577236  \n",
       "4253                    8.0    0.670325  \n",
       "4254                    9.0    1.359447  \n",
       "4255                   11.5    1.740191  \n",
       "\n",
       "[4256 rows x 4 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[12:16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>277.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.052388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>328.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.584183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>56.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.388913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>1224.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.124628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>103.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.014478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>613.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.176986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>64.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.640324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>1510.5</td>\n",
       "      <td>100.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.376997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>1173.5</td>\n",
       "      <td>60.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.151484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>651.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.487004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2979 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      authors_citations_median  authors_publications_median  \\\n",
       "1091                     277.0                         29.0   \n",
       "382                      328.5                         23.5   \n",
       "2743                      56.0                         14.0   \n",
       "3150                    1224.0                         27.0   \n",
       "2230                     103.5                         12.5   \n",
       "...                        ...                          ...   \n",
       "3444                     613.5                         59.5   \n",
       "466                       64.0                         19.0   \n",
       "3092                    1510.5                        100.5   \n",
       "3772                    1173.5                         60.5   \n",
       "860                      651.5                         24.5   \n",
       "\n",
       "      authors_hindex_median  reputation  \n",
       "1091                    7.0    1.052388  \n",
       "382                     6.5    1.584183  \n",
       "2743                    4.0    1.388913  \n",
       "3150                   13.0    2.124628  \n",
       "2230                    3.0    1.014478  \n",
       "...                     ...         ...  \n",
       "3444                   11.0    1.176986  \n",
       "466                     4.0    0.640324  \n",
       "3092                   19.0    1.376997  \n",
       "3772                   18.0    1.151484  \n",
       "860                    10.0    1.487004  \n",
       "\n",
       "[2979 rows x 4 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df[df.columns[12:16]]\n",
    "y = df['ratings']\n",
    "X_train, X_test, y_train, y_test = split_data(X,y,0.3)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4\n",
    "\n",
    "Experiment with training a different regressor, a [Gradient Boosting Regressor](https://scikit-learn.org/stable/modules/ensemble.html?highlight=xgboost#gradient-boosting). This regressor is analogous to the Gradient Boosting Classifier that you have seen in class. This model performs extremely well for a variety of tasks and is often used in machine learning competitions for tabular data (e.g., on [Kaggle](www.kaggle.com)). You must:\n",
    "\n",
    "1. Train a Gradient Boosting Regressor without specifying any parameters, e.g. `GradientBoostingRegressor().fit(X, y)`, and report its $R^2$ on the testing set. Your model should again use as features:\n",
    "    - Median values for the number of author citations, publications and h-indexes as calculated in Task 1.1.1.\n",
    "    - `reputation` of the last author, as calculated in Task 1.1.2.\n",
    "2. Create an additional feature called $crazy$, which is derived as follows. If the score  of the paper, $ratings$, is bigger than 4.96, then $crazy = 9 - ratings$, otherwise, $crazy = - ratings$. Train a Gradient Boosting Regressor to predict paper scores using only $crazy$ as a feature. Additionally, train a Linear Regression model to predict paper scores using only $crazy$ as a feature. Report the $R^2$ in the testing set.\n",
    "3. **Discuss:** Why does the Gradient Boosting Regressor perform so much better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11823779844494087"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "est = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "pred = est.predict(X_test)\n",
    "R2 = metrics.r2_score(y_test,pred) #get the r2 score can be other score like F1 or accurancy\n",
    "R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999578690184099"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df['crazy']\n",
    "y = df['ratings']\n",
    "X_train_crazy, X_test_crazy, y_train_crazy, y_test_crazy = split_data(X,y,0.3)\n",
    "X_train_crazy = np.array(X_train_crazy).reshape(-1,1)\n",
    "X_test_crazy = np.array(X_test_crazy).reshape(-1,1)\n",
    "est = GradientBoostingRegressor().fit(X_train_crazy, y_train_crazy)\n",
    "pred = est.predict(X_test_crazy)\n",
    "R2 = metrics.r2_score(y_test_crazy,pred) #get the r2 score can be other score like F1 or accurancy\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.5\n",
    "\n",
    "Complex models often have several hyper-parameters. \n",
    "To obtain the best results, it is common-place to use a cross-validation set-up in your training data to find the best hyper-parameters, and then use it for the test set.\n",
    "\n",
    "\n",
    "1. Write modular code (i.e., a function) to divide your training data into $N$ folds and perform cross-validation.\n",
    "2.  Experiment tuning two hyper-parameters of the Gradient Boosting Regressor: `n_estimators` and `learning_rate`.\n",
    "For each possible combination of the two hyper-parameters (see below for the range of values that you should try for each hyper-parameter), train your model in a cross-validation setup with $N$=20. Report the mean $R^2$ along with the 90% CI for the 18 scenarios. Notice that you can calculate the 90% CI in a bootstrap-like fashion.\n",
    "    - `n_estimators`$ \\in  \\{ 50, 75, 100, 150, 200, 250\\}$\n",
    "    - `learning_rate`$ \\in  \\{ 0.1, 0.05, 0.01\\}$.\n",
    "3. With the best hyper-parameters obtained, train your model with the entire training set and report the $R^2$ on the testing set.\n",
    "4. **Discuss:** Why don't we tune the hyper-parameters in the testing set instead of doing cross-validation in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.1, 0.05, 0.01],\n",
       "                         'n_estimators': [50, 75, 100, 150, 200, 250]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "est = GradientBoostingRegressor()\n",
    "parameters = {'n_estimators' : [50,75,100,150,200,250] ,\n",
    "              'learning_rate' : [0.1,0.05,0.01]}\n",
    "y = df['ratings']\n",
    "X = df[df.columns[12:16]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = .3)\n",
    "cross_vl = GridSearchCV(est , parameters , cv = 20 , scoring='r2')\n",
    "cross_vl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'n_estimators': 250}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_vl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_vl.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.18099768, 0.31537557, 0.391766  , 0.55538856, 0.75131768,\n",
       "        0.81514863, 0.15161382, 0.22109814, 0.3013965 , 0.44803984,\n",
       "        0.60597171, 0.80263959, 0.17590358, 0.24534286, 0.29999384,\n",
       "        0.45683823, 0.65159149, 0.89251627]),\n",
       " 'std_fit_time': array([0.01315091, 0.03035754, 0.01947791, 0.02410665, 0.04532374,\n",
       "        0.04883308, 0.00406219, 0.00720091, 0.00874075, 0.02267238,\n",
       "        0.05027948, 0.06432291, 0.00652138, 0.00947848, 0.01218116,\n",
       "        0.01642855, 0.03631737, 0.09449635]),\n",
       " 'mean_score_time': array([0.00260308, 0.00324841, 0.00303935, 0.00304083, 0.00343602,\n",
       "        0.00279193, 0.00234921, 0.00209639, 0.00214908, 0.00243777,\n",
       "        0.00249368, 0.00270045, 0.00269612, 0.00239644, 0.00220171,\n",
       "        0.00244013, 0.0029449 , 0.00349485]),\n",
       " 'std_score_time': array([0.00065784, 0.00054163, 0.00097756, 0.00058871, 0.00086861,\n",
       "        0.0006816 , 0.00057929, 0.00030489, 0.00035432, 0.00049372,\n",
       "        0.00049262, 0.00045472, 0.0007134 , 0.00048567, 0.00040146,\n",
       "        0.00049185, 0.00059316, 0.00067   ]),\n",
       " 'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 75, 100, 150, 200, 250, 50, 75, 100, 150, 200, 250,\n",
       "                    50, 75, 100, 150, 200, 250],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.1, 'n_estimators': 50},\n",
       "  {'learning_rate': 0.1, 'n_estimators': 75},\n",
       "  {'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.1, 'n_estimators': 150},\n",
       "  {'learning_rate': 0.1, 'n_estimators': 200},\n",
       "  {'learning_rate': 0.1, 'n_estimators': 250},\n",
       "  {'learning_rate': 0.05, 'n_estimators': 50},\n",
       "  {'learning_rate': 0.05, 'n_estimators': 75},\n",
       "  {'learning_rate': 0.05, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.05, 'n_estimators': 150},\n",
       "  {'learning_rate': 0.05, 'n_estimators': 200},\n",
       "  {'learning_rate': 0.05, 'n_estimators': 250},\n",
       "  {'learning_rate': 0.01, 'n_estimators': 50},\n",
       "  {'learning_rate': 0.01, 'n_estimators': 75},\n",
       "  {'learning_rate': 0.01, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.01, 'n_estimators': 150},\n",
       "  {'learning_rate': 0.01, 'n_estimators': 200},\n",
       "  {'learning_rate': 0.01, 'n_estimators': 250}],\n",
       " 'split0_test_score': array([0.1231314 , 0.12255585, 0.11554419, 0.11747422, 0.10869728,\n",
       "        0.10088279, 0.12698507, 0.1310398 , 0.12463712, 0.12972115,\n",
       "        0.13661853, 0.13783689, 0.06463116, 0.08131429, 0.09189648,\n",
       "        0.10719587, 0.11854764, 0.12424335]),\n",
       " 'split1_test_score': array([0.07513258, 0.0681146 , 0.07298478, 0.03726069, 0.02457156,\n",
       "        0.01539586, 0.09298095, 0.09456684, 0.08903628, 0.0868057 ,\n",
       "        0.0786627 , 0.07233962, 0.05174431, 0.06607707, 0.07555612,\n",
       "        0.08872902, 0.09461131, 0.09501617]),\n",
       " 'split2_test_score': array([0.07828327, 0.08072096, 0.07659559, 0.06342023, 0.04767085,\n",
       "        0.0305848 , 0.08474704, 0.07990486, 0.08253941, 0.07682235,\n",
       "        0.07700051, 0.0713257 , 0.05414947, 0.06692941, 0.07482406,\n",
       "        0.08173642, 0.08280688, 0.08478275]),\n",
       " 'split3_test_score': array([0.10178942, 0.10655508, 0.11322539, 0.10653437, 0.0953341 ,\n",
       "        0.08661188, 0.10377899, 0.10698149, 0.10506797, 0.10948967,\n",
       "        0.10864205, 0.1086513 , 0.0572595 , 0.07216444, 0.08252765,\n",
       "        0.0922317 , 0.10097117, 0.10199928]),\n",
       " 'split4_test_score': array([0.05202893, 0.05528678, 0.05309541, 0.03850515, 0.02458122,\n",
       "        0.00529125, 0.04768031, 0.05296042, 0.05317958, 0.0517669 ,\n",
       "        0.05112408, 0.05037911, 0.02101451, 0.03059554, 0.03596185,\n",
       "        0.04283582, 0.04764125, 0.04809109]),\n",
       " 'split5_test_score': array([0.0858953 , 0.07854976, 0.0690761 , 0.0585757 , 0.02992294,\n",
       "        0.02913287, 0.08737239, 0.08787913, 0.08137803, 0.08797821,\n",
       "        0.07572466, 0.06246784, 0.0420811 , 0.05357425, 0.06383538,\n",
       "        0.07837836, 0.0840644 , 0.08674652]),\n",
       " 'split6_test_score': array([ 0.06447905,  0.05591638,  0.04449341,  0.0290184 ,  0.00837325,\n",
       "        -0.00835397,  0.07097739,  0.06254666,  0.05605146,  0.04473686,\n",
       "         0.0364424 ,  0.02296203,  0.05626419,  0.06524209,  0.06896822,\n",
       "         0.07103539,  0.06967931,  0.06873136]),\n",
       " 'split7_test_score': array([0.15429032, 0.15899127, 0.16168744, 0.14284219, 0.1355947 ,\n",
       "        0.12915629, 0.15504282, 0.15853344, 0.1598884 , 0.15856746,\n",
       "        0.15666201, 0.1523827 , 0.08075759, 0.10044371, 0.1157266 ,\n",
       "        0.13557088, 0.14782443, 0.15386128]),\n",
       " 'split8_test_score': array([0.08023339, 0.08121816, 0.07974846, 0.06340046, 0.05747707,\n",
       "        0.04371899, 0.05638553, 0.05865124, 0.05803373, 0.06452672,\n",
       "        0.06589876, 0.06127049, 0.0345765 , 0.04977267, 0.05521513,\n",
       "        0.06269871, 0.06420289, 0.06235728]),\n",
       " 'split9_test_score': array([0.13681493, 0.14028449, 0.14656086, 0.14500544, 0.1518609 ,\n",
       "        0.14630348, 0.14528355, 0.14805732, 0.14712809, 0.14522557,\n",
       "        0.14395413, 0.15150031, 0.08300354, 0.10206451, 0.11648349,\n",
       "        0.13372842, 0.14155884, 0.1443942 ]),\n",
       " 'split10_test_score': array([0.10005609, 0.09223294, 0.07904522, 0.04479984, 0.0329667 ,\n",
       "        0.03344512, 0.10820157, 0.1020677 , 0.09747039, 0.08953591,\n",
       "        0.08046604, 0.06637377, 0.06974443, 0.0839807 , 0.09395289,\n",
       "        0.10667906, 0.11200237, 0.11383263]),\n",
       " 'split11_test_score': array([0.1036475 , 0.11042494, 0.11255249, 0.11349793, 0.1199295 ,\n",
       "        0.10588116, 0.09372586, 0.10074275, 0.10396558, 0.10431023,\n",
       "        0.1051224 , 0.10860642, 0.04100461, 0.05637656, 0.06693761,\n",
       "        0.08131404, 0.08845285, 0.09170763]),\n",
       " 'split12_test_score': array([ 0.01998489,  0.00354514,  0.00217969,  0.00736079, -0.00460022,\n",
       "        -0.01002563,  0.02286656,  0.02124376,  0.02228915,  0.02388276,\n",
       "         0.01891686,  0.01527458,  0.02779005,  0.02940072,  0.02878227,\n",
       "         0.02727633,  0.02489501,  0.02321022]),\n",
       " 'split13_test_score': array([ 0.01410579,  0.01093636,  0.00745126, -0.00386157, -0.00149343,\n",
       "        -0.00650374,  0.01490257,  0.01600407,  0.01293404,  0.00668073,\n",
       "         0.01048143,  0.01172951,  0.01073536,  0.01649394,  0.01851318,\n",
       "         0.02072945,  0.0185613 ,  0.01587458]),\n",
       " 'split14_test_score': array([0.09790453, 0.10252447, 0.10684627, 0.11195099, 0.09909656,\n",
       "        0.08188804, 0.10853328, 0.10874384, 0.10676927, 0.11538401,\n",
       "        0.11582757, 0.11408785, 0.06492407, 0.0816686 , 0.09246501,\n",
       "        0.10336987, 0.10975605, 0.10994964]),\n",
       " 'split15_test_score': array([0.04452956, 0.04794472, 0.04622177, 0.04374931, 0.04030985,\n",
       "        0.04004217, 0.05030305, 0.04997807, 0.04762622, 0.0466698 ,\n",
       "        0.04518553, 0.04098522, 0.02889409, 0.03690178, 0.04224406,\n",
       "        0.04742802, 0.04992423, 0.0506296 ]),\n",
       " 'split16_test_score': array([0.16547267, 0.15816382, 0.15502864, 0.14369767, 0.1365206 ,\n",
       "        0.11988534, 0.15953029, 0.16523874, 0.16569535, 0.16199047,\n",
       "        0.15066535, 0.13941157, 0.0727986 , 0.09976053, 0.11675108,\n",
       "        0.14158781, 0.15290017, 0.15963799]),\n",
       " 'split17_test_score': array([0.07282445, 0.07547693, 0.06659554, 0.05089067, 0.0336735 ,\n",
       "        0.03562421, 0.07678529, 0.07383781, 0.07476147, 0.07238476,\n",
       "        0.0739505 , 0.071279  , 0.04337966, 0.05827308, 0.0659484 ,\n",
       "        0.07340559, 0.0764928 , 0.0772493 ]),\n",
       " 'split18_test_score': array([0.07389355, 0.06459429, 0.0670252 , 0.05187385, 0.03874432,\n",
       "        0.01799209, 0.08794817, 0.08405092, 0.08197167, 0.07061305,\n",
       "        0.07116317, 0.06677247, 0.05571856, 0.07046723, 0.07906467,\n",
       "        0.0858447 , 0.08797193, 0.08876383]),\n",
       " 'split19_test_score': array([0.11260979, 0.11757471, 0.12335755, 0.11211597, 0.10701549,\n",
       "        0.1063008 , 0.09454865, 0.09397826, 0.10383922, 0.11284408,\n",
       "        0.10897817, 0.10306366, 0.05609313, 0.06954664, 0.07899595,\n",
       "        0.08748232, 0.09402047, 0.09631081]),\n",
       " 'mean_test_score': array([0.08785537, 0.08658058, 0.08496576, 0.07390561, 0.06431234,\n",
       "        0.05516269, 0.08942896, 0.08985036, 0.08871312, 0.08799682,\n",
       "        0.08557434, 0.081435  , 0.05082822, 0.06455239, 0.07323251,\n",
       "        0.08346289, 0.08834426, 0.08986948]),\n",
       " 'std_test_score': array([0.03864872, 0.0411489 , 0.04315141, 0.04496113, 0.04849894,\n",
       "        0.04846817, 0.03847676, 0.03979042, 0.04016974, 0.04147719,\n",
       "        0.04121271, 0.04257362, 0.01909966, 0.02336747, 0.02713172,\n",
       "        0.03240913, 0.03594967, 0.03802421]),\n",
       " 'rank_test_score': array([ 7,  8, 10, 13, 16, 17,  3,  2,  4,  6,  9, 12, 18, 15, 14, 11,  5,\n",
       "         1])}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_vl.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09376653, 0.08793676, 0.08128261, 0.06845365, 0.05365106,\n",
       "       0.03939912, 0.09753827, 0.09636483, 0.09529208, 0.08882359,\n",
       "       0.08309165, 0.07732915, 0.05884747, 0.07337457, 0.08272786,\n",
       "       0.09257139, 0.09639948, 0.09669139])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_vl.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_vl.cv_results_['rank_test_score'][cross_vl.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05, 'n_estimators': 50}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_vl.cv_results_['params'][cross_vl.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09753827147942182"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_vl.cv_results_['mean_test_score'][cross_vl.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our best R2 is equal to :  9.75 % with the parameter {'learning_rate': 0.05, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print('Our best R2 is equal to : ',round(cross_vl.cv_results_['mean_test_score'][cross_vl.best_index_]*100,2),'% with the parameter',cross_vl.cv_results_['params'][cross_vl.best_index_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Step 2:_ What influences papers getting accepted?\n",
    "\n",
    "Time to change hats!\n",
    "\n",
    "If before we were interested in creating an accurate regressor, now we are interested in understanding what increases the chance of papers getting accepted. \n",
    "\n",
    "Typically, in that scenario, simpler models with a clear statistical interpretation (e.g. logistic regression) yield more interesting insights.\n",
    "\n",
    "For the analysis in this and the next step, you should use [statsmodels](https://www.statsmodels.org/) (for the regressions) and [scipy](https://www.scipy.org/) (for the statistical hypothesis testing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1\n",
    "\n",
    "Let's warm up with some visualizations and some hypothesis testing!\n",
    "\n",
    "1. Plot the distributions of 1) ratings of papers that got accepted in 2020, 2) ratings of papers that got rejected in 2020.\n",
    "2. Select a statistical test to compare whether the mean for ratings of papers that got accepted in 2020 is significantly higher.\n",
    "3. **Discuss:** Justify why the statistical test you selected is appropriate. Interpret the test-related statistic and its p-value: concretely, what do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper2020 = df.loc[df['year']==2020]\n",
    "g = sns.FacetGrid(paper2020, col='decisions',margin_titles=True, height=5)\n",
    "g.map(plt.hist, 'ratings')\n",
    "plt.suptitle('Paper 2020')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept2020 = df.loc[(df['decisions']=='Accept')&(df['year']==2020)]\n",
    "reject2020 = df.loc[(df['decisions']=='Reject')&(df['year']==2020)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "set2 = reject2020['ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.683274771609272"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.138632750397448"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = accept2020['ratings']\n",
    "set1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:        mean = 6.1386, variance = 0.6497, skew = -0.3754, kurtosis = 0.6991\n"
     ]
    }
   ],
   "source": [
    "n1, (smin1, smax1), sm1, sv1, ss1, sk1 = stats.describe(set1)\n",
    "n2, (smin2, smax2), sm2, sv2, ss2, sk2 = stats.describe(set2)\n",
    "sstr = '%-14s mean = %6.4f, variance = %6.4f, skew = %6.4f, kurtosis = %6.4f'\n",
    "print(sstr % ('sample:', sm1, sv1, ss1, sk1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:        mean = 3.6833, variance = 1.5206, skew = -0.0948, kurtosis = -0.4669\n"
     ]
    }
   ],
   "source": [
    "print(sstr % ('sample:', sm2, sv2, ss2, sk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3405172702400407"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv2/sv1 #<4 ----> donc variance are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic = 45.798 pvalue = 0.0000\n"
     ]
    }
   ],
   "source": [
    "print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_ind(set1,set2, equal_var=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two hypotheses for this particular two sample t-test are as follows:\n",
    "\n",
    "H0: µ1 = µ2 (the two population means are equal)\n",
    "\n",
    "HA: µ1 ≠µ2 (the two population means are not equal)\n",
    "\n",
    "So as we have pvalue < 0.05 we acce H0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2\n",
    "\n",
    "We will now carry out a logistic regression modeling the binary variable `decisions` as a function of the continuous variable `ratings` and an intercept. \n",
    "\n",
    "Recall that a logistic regression is a model in the form:\n",
    "\n",
    "$$\n",
    "\\log \\Big( \\frac{p}{1-p} \\Big) = b_0 + b_1x_1 + b_2x_2 + \\ldots\n",
    "$$\n",
    "\n",
    "Where $p$ is the probability of the dependent variable (here, `decisions`) being equals to 1. \n",
    "Note that $\\frac{p}{1-p}$ represents the odds of the variable, and thus, on the left-hand side we have the log-odds of the variable.\n",
    "This can be also written as:\n",
    "\n",
    "$$\n",
    "\\Big( \\frac{p}{1-p} \\Big) = e^{b_0 + b_1 x_1 + b_2 x_2 + \\ldots} =  e^{b_0} e^{b_1 x_1} e^{b_2 x_2} \\ldots\n",
    "$$\n",
    "\n",
    "Given a linear variable, say $x_1$, if we increase the value associated with this variable by a single unit, and keep everything constant, we have:\n",
    "\n",
    "$$\n",
    " e^{b_1(x_1+1)} =  e^{b_1 x_1 + b_1} = e^{b_1 x_1}e^{b_1}  \n",
    "$$\n",
    "\n",
    "This means that we multiply the odds of the outcome variable by $e^{b_1}$. Thus, let's say that $x_1$ is the average rating, and $\\beta_1$ is the associated coefficient. Also, let's assume that $\\beta_1$ equals 2. In that case, increasing the score of the paper by 1 unit is equivalent to multiplying both sides of the previous equation by $e^{b_1}$. The original equation for our model becomes:\n",
    "\n",
    "$$\n",
    "\\Big( \\frac{p}{1-p} \\Big) = e^{b_0} e^{b_1 x_1} \n",
    "$$\n",
    "$$\n",
    "\\Big( \\frac{p}{1-p} \\Big) e^{b_1}  = e^{b_0} e^{b_1 x_1} e^{b_1}\n",
    "$$\n",
    "\n",
    "Since $b_1=2$, we have that this is the same as multiplying the odds of the variable by $e^2\\approx7$. \n",
    "So for example, if a paper with a score 5 had $p=0.05$ of being approved, its odds would be $0.05/0.95\\approx0.052$. According to our model, an increase in 1-rating point would mean that the new odds would be $0.052*7\\approx0.36$. Using the odds formula  ($\\frac{p}{1-p}$), this suggests that this paper would have a chance of $0.56$ of being accepted.\n",
    "\n",
    "---\n",
    "\n",
    "This is the theory. Now, let's find out what the real world looks like.\n",
    "\n",
    "\n",
    "1. Fit a logistic regression model to our data considering as the training set all papers submitted in 2020. Your model should predict a binary variable related to decisions (which equals true if the paper was accepted and false otherwise) as a function of the paper ratings and an intercept. In mathematical notation:\n",
    "$$\n",
    "d = b_0 + r b_1\n",
    "$$\n",
    "Where $d$ is the binary variable corresponding to a decision, $r$ is a numeric variable corresponding to the rating a paper has received and $b$ are coefficients.\n",
    "Notice that here we have no testing set!\n",
    "Report the summary of your model. \n",
    "2. **Discuss:** Interpreting the coefficients of your model, calculate the probability that a paper with a score 7 will be accepted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings</th>\n",
       "      <th>decisions</th>\n",
       "      <th>institution</th>\n",
       "      <th>csranking</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors_citations</th>\n",
       "      <th>authors_publications</th>\n",
       "      <th>authors_hindex</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "      <th>crazy</th>\n",
       "      <th>has_top_company</th>\n",
       "      <th>has_top_institution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>2020</td>\n",
       "      <td>On the Dynamics and Convergence of Weight Norm...</td>\n",
       "      <td>Yonatan Dukler;Quanquan Gu;Guido Montufar</td>\n",
       "      <td>-0.27377</td>\n",
       "      <td>0</td>\n",
       "      <td>University of California, Los Angeles;Universi...</td>\n",
       "      <td>20;20;20</td>\n",
       "      <td>1</td>\n",
       "      <td>9;3895;1193</td>\n",
       "      <td>6;174;60</td>\n",
       "      <td>1;34;14</td>\n",
       "      <td>False</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.3198</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                                              paper  \\\n",
       "3401  2020  On the Dynamics and Convergence of Weight Norm...   \n",
       "\n",
       "                                        authors  ratings  decisions  \\\n",
       "3401  Yonatan Dukler;Quanquan Gu;Guido Montufar -0.27377          0   \n",
       "\n",
       "                                            institution csranking categories  \\\n",
       "3401  University of California, Los Angeles;Universi...  20;20;20          1   \n",
       "\n",
       "     authors_citations authors_publications authors_hindex  arxiv  \\\n",
       "3401       9;3895;1193             6;174;60        1;34;14  False   \n",
       "\n",
       "      authors_citations_median  authors_publications_median  \\\n",
       "3401                    1193.0                         60.0   \n",
       "\n",
       "      authors_hindex_median  reputation  crazy  has_top_company  \\\n",
       "3401                   14.0      1.3198    5.0                0   \n",
       "\n",
       "      has_top_institution  \n",
       "3401                    1  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper2020.sample(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-245-e32ca63e170a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  paper2020['decisions'] = paper2020['decisions'].apply(lambda x : 1 if x=='Accept' else 0)\n"
     ]
    }
   ],
   "source": [
    "paper2020 = df.loc[df['year']==2020]\n",
    "paper2020['decisions'] = paper2020['decisions'].apply(lambda x : 1 if x=='Accept' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings</th>\n",
       "      <th>decisions</th>\n",
       "      <th>institution</th>\n",
       "      <th>csranking</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors_citations</th>\n",
       "      <th>authors_publications</th>\n",
       "      <th>authors_hindex</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "      <th>crazy</th>\n",
       "      <th>has_top_company</th>\n",
       "      <th>has_top_institution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>2020</td>\n",
       "      <td>SAFE-DNN: A Deep Neural Network with Spike Ass...</td>\n",
       "      <td>Xueyuan She;Priyabrata Saha;Daehyun Kim;Yun Lo...</td>\n",
       "      <td>-0.273770</td>\n",
       "      <td>0</td>\n",
       "      <td>Georgia Institute of Technology;Georgia Instit...</td>\n",
       "      <td>13;13;13;13;13</td>\n",
       "      <td>0</td>\n",
       "      <td>32;26;285;571;314</td>\n",
       "      <td>8;15;72;102;90</td>\n",
       "      <td>3;3;8;12;8</td>\n",
       "      <td>False</td>\n",
       "      <td>285.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.190636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>2020</td>\n",
       "      <td>Retrieving Signals in the Frequency Domain wit...</td>\n",
       "      <td>Chiheb Trabelsi;Olexa Bilaniuk;Ousmane Dia;Yin...</td>\n",
       "      <td>0.354264</td>\n",
       "      <td>0</td>\n",
       "      <td>Polytechnique Montreal;University of Montreal;...</td>\n",
       "      <td>390;128;-1;-1;128;128;-1;-1</td>\n",
       "      <td>0</td>\n",
       "      <td>286;281;5;18;763;693;389;8489</td>\n",
       "      <td>11;14;8;21;37;28;32;120</td>\n",
       "      <td>4;7;1;3;18;10;10;33</td>\n",
       "      <td>False</td>\n",
       "      <td>337.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.990237</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>2020</td>\n",
       "      <td>Graph Warp Module: an Auxiliary Module for Boo...</td>\n",
       "      <td>Katsuhiko Ishiguro;Shin-ichi Maeda;Masanori Ko...</td>\n",
       "      <td>0.354264</td>\n",
       "      <td>0</td>\n",
       "      <td>Preferred Networks, Inc.;Preferred Networks, I...</td>\n",
       "      <td>-1;-1;-1</td>\n",
       "      <td>8</td>\n",
       "      <td>628;2028;2498</td>\n",
       "      <td>73;99;35</td>\n",
       "      <td>14;21;12</td>\n",
       "      <td>True</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.997114</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                                              paper  \\\n",
       "3215  2020  SAFE-DNN: A Deep Neural Network with Spike Ass...   \n",
       "3181  2020  Retrieving Signals in the Frequency Domain wit...   \n",
       "3588  2020  Graph Warp Module: an Auxiliary Module for Boo...   \n",
       "\n",
       "                                                authors   ratings  decisions  \\\n",
       "3215  Xueyuan She;Priyabrata Saha;Daehyun Kim;Yun Lo... -0.273770          0   \n",
       "3181  Chiheb Trabelsi;Olexa Bilaniuk;Ousmane Dia;Yin...  0.354264          0   \n",
       "3588  Katsuhiko Ishiguro;Shin-ichi Maeda;Masanori Ko...  0.354264          0   \n",
       "\n",
       "                                            institution  \\\n",
       "3215  Georgia Institute of Technology;Georgia Instit...   \n",
       "3181  Polytechnique Montreal;University of Montreal;...   \n",
       "3588  Preferred Networks, Inc.;Preferred Networks, I...   \n",
       "\n",
       "                        csranking categories              authors_citations  \\\n",
       "3215               13;13;13;13;13          0              32;26;285;571;314   \n",
       "3181  390;128;-1;-1;128;128;-1;-1          0  286;281;5;18;763;693;389;8489   \n",
       "3588                     -1;-1;-1          8                  628;2028;2498   \n",
       "\n",
       "         authors_publications       authors_hindex  arxiv  \\\n",
       "3215           8;15;72;102;90           3;3;8;12;8  False   \n",
       "3181  11;14;8;21;37;28;32;120  4;7;1;3;18;10;10;33  False   \n",
       "3588                 73;99;35             14;21;12   True   \n",
       "\n",
       "      authors_citations_median  authors_publications_median  \\\n",
       "3215                     285.0                         72.0   \n",
       "3181                     337.5                         24.5   \n",
       "3588                    2028.0                         73.0   \n",
       "\n",
       "      authors_hindex_median  reputation  crazy  has_top_company  \\\n",
       "3215                    8.0   -1.190636    5.0                0   \n",
       "3181                    8.5    0.990237   -5.0                0   \n",
       "3588                   14.0    0.997114   -5.0                0   \n",
       "\n",
       "      has_top_institution  \n",
       "3215                    1  \n",
       "3181                    1  \n",
       "3588                    0  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper2020.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.251882\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              decisions   No. Observations:                 2052\n",
      "Model:                          Logit   Df Residuals:                     2050\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.5913\n",
      "Time:                        16:01:08   Log-Likelihood:                -516.86\n",
      "converged:                       True   LL-Null:                       -1264.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -12.8811      0.597    -21.574      0.000     -14.051     -11.711\n",
      "ratings        2.3672      0.110     21.438      0.000       2.151       2.584\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "mod = smf.logit(formula='decisions ~ ratings' , data = paper2020)\n",
    "res= mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "log_reg = LogisticRegression(fit_intercept=True)  # create the model\n",
    "paper2020 = df.loc[df['year']==2020]\n",
    "#X_train = paper2020.drop(['decisions','paper','authors','institution','csranking','authors_hindex','authors_citations','authors_publications'],axis=1)\n",
    "X_train = paper2020[['ratings']]\n",
    "y_train = paper2020['decisions'].apply(lambda x : 1 if x=='Accept' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)  # train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3391165899082815 * ratings + \n",
      "-12.730478459704877\n"
     ]
    }
   ],
   "source": [
    "for f in range(0,len(X_train.columns)):\n",
    "    print(\"{0} * {1} + \".format(log_reg.coef_[0][f], X_train.columns[f]))\n",
    "print(log_reg.intercept_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3\n",
    "\n",
    "Our model is not so interesting since the only independent variable (that is, our model' feature or predictor) is something blatantly associated with paper acceptance. Let's go further! \n",
    "\n",
    "1. Run a logistic regression with the binary decision as the dependent variable (the outcome) and using as independent variables (the features): ratings, the reputation of the last author, and whether the paper was on arxiv or not. That is, in [patsy-style formula](https://patsy.readthedocs.io/en/latest/formulas.html): `decisions ~ ratings + reputation + arxiv` (variable names do not need to be exactly these). Consider all papers submitted in 2020 as your training data.\n",
    "Notice that reputation was calculated in Task 1.1. \n",
    "2. **Discuss:** Unlike `ratings` and `reputation`, the variable `arxiv` is binary. Following the same logic as we did for continuous variables in the text of Task 2.2, interpret the meaning of this coefficient. What happens to the odds ratio if the paper was seen in arxiv? Is this effect statistically significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Statmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper2020 = df.loc[df['year']==2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-224-26335df3789a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  paper2020['decisions'] = paper2020['decisions'].apply(lambda x : 1 if x=='Accept'\n"
     ]
    }
   ],
   "source": [
    "paper2020['decisions'] = paper2020['decisions'].apply(lambda x : 1 if x=='Accept'\n",
    "                                                 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.250440\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              decisions   No. Observations:                 2052\n",
      "Model:                          Logit   Df Residuals:                     2048\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.5936\n",
      "Time:                        15:51:20   Log-Likelihood:                -513.90\n",
      "converged:                       True   LL-Null:                       -1264.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept       -13.2261      0.634    -20.873      0.000     -14.468     -11.984\n",
      "arxiv[T.True]     0.2890      0.167      1.727      0.084      -0.039       0.617\n",
      "ratings           2.3541      0.111     21.296      0.000       2.137       2.571\n",
      "reputation        0.2267      0.148      1.533      0.125      -0.063       0.517\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "mod = smf.logit(formula='decisions ~ ratings + reputation + arxiv' , data =paper2020)\n",
    "res= mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "log_reg = LogisticRegression()\n",
    "X_train = paper2020[['ratings','arxiv','reputation']]\n",
    "y_train = paper2020['decisions'].apply(lambda x : 1 if x=='Accept'\n",
    "                                                 else 0)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.326095073953047"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.coef_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.326095073953047 * ratings + \n",
      "0.2814665530259435 * arxiv + \n",
      "0.22254585322636183 * reputation + \n",
      "-13.067313325364816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for f in range(0,len(X_train.columns)):\n",
    "    print(\"{0} * {1} + \".format(log_reg.coef_[0][f], X_train.columns[f]))\n",
    "print(log_reg.intercept_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4\n",
    "\n",
    "Let's finally move on to the question that you have been dying to answer: Do pre-prints favor top institutions? \n",
    "\n",
    "In order to (try to) answer that question, you must fit yet another logistic regression.\n",
    "\n",
    "Your regression should have the paper decision as the dependent variable, and `ratings`, `reputation`, and `arxiv` as independent variables just like in task 2.3. Yet, here, include also as independent variables the binary variable `has_top_institution`, which equals 1 if the paper has an author in a top-10 institution; and the interaction variable `arxiv:has_top_institution`, which equals one only if the paper is from a top-10 institution **and** if it appeared on arxiv before the submission deadline. In patsy-style formula your model should look something like: \n",
    "\n",
    "`decisions_bool ~ ratings + reputation + arxiv + has_top_institution + arxiv:has_top_institution`\n",
    "\n",
    "\n",
    "1. Fit this model and estimate the effect of posting on arxiv for a top institution. Again, consider only papers submitted in the 2020 edition.\n",
    "2. **Discuss:** Interpreting the p-values, discuss: is this evidence that arxiv breaks double-blind submissions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper2020_ = df.loc[df['year']==2020].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2204    0\n",
       "2205    0\n",
       "2206    0\n",
       "2207    0\n",
       "2208    0\n",
       "       ..\n",
       "4251    0\n",
       "4252    0\n",
       "4253    0\n",
       "4254    0\n",
       "4255    0\n",
       "Name: has_top_institution, Length: 2052, dtype: int32"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper2020_['has_top_institution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper2020_['decisions'] = paper2020_['decisions'].apply(lambda x : 1 if x=='Accept'\n",
    "                                                 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.247320\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              decisions   No. Observations:                 2052\n",
      "Model:                          Logit   Df Residuals:                     2046\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.5987\n",
      "Time:                        17:28:46   Log-Likelihood:                -507.50\n",
      "converged:                       True   LL-Null:                       -1264.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                          -13.3940      0.647    -20.717      0.000     -14.661     -12.127\n",
      "C(arxiv)[T.True]                     0.1061      0.200      0.529      0.597      -0.287       0.499\n",
      "C(has_top_institution)[T.1]          0.4373        nan        nan        nan         nan         nan\n",
      "ratings                              2.3834      0.113     21.171      0.000       2.163       2.604\n",
      "reputation                           0.1605      0.150      1.072      0.284      -0.133       0.454\n",
      "arxiv[False]:has_top_institution    -0.0710        nan        nan        nan         nan         nan\n",
      "arxiv[True]:has_top_institution      0.5083        nan        nan        nan         nan         nan\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "mod = smf.logit(formula='decisions ~ ratings + reputation + C(arxiv) + C(has_top_institution) + arxiv:has_top_institution' , data =paper2020_)\n",
    "res= mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Matching\n",
    "\n",
    "Okay, so let's change hats one last time.\n",
    "\n",
    "As you have all seen in class, a particularly powerful way of disentangling causal effects from observational data is through matching: making sure we are not comparing apples to oranges.\n",
    "\n",
    "\n",
    "### Task 3.1\n",
    "\n",
    "One of the ways to do matching is called \"Propensity Score Matching.\" There, we calculate a *propensity score* for each subject which represents the propensity to receive a \"treatment.\" Then, we match subjects who received and did not receive the treatment, but that had similar propensity scores (that is, even though some received the treatment and some did not, they had similar chances to receive it).\n",
    "\n",
    "In our specific case, we can further attempt to study the impact of pre-prints by considering publishing to arxiv as our \"treatment\".\n",
    "\n",
    "In that context, the first step to perform propensity score matching is to create a classifier that predicts whether a paper was published on arxiv or not.\n",
    "\n",
    "1. We have trained this classifier for you (don't get spoiled!). You may load the pandas dataframe entitled `propensity_scores.csv.gz` from the github repo. \n",
    "Notice that we will be using only the articles published in 2020. \n",
    "Create a new dataframe that is a merged version of this new dataframe with the dataframe you have been working on so far. Remember to keep only the papers published in 2020!\n",
    "2. **Discuss:** In which way is this classifier (that is a classifier trained to estimate propensity scores) different from the regressor that you trained in Step 1?\n",
    "\n",
    "**Hint:** For this classifier we don't need a training set and a testing set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.360486\n",
       "1       0.567842\n",
       "2       0.334322\n",
       "3       0.402644\n",
       "4       0.334322\n",
       "          ...   \n",
       "2047    0.306323\n",
       "2048    0.219910\n",
       "2049    0.208421\n",
       "2050    0.213840\n",
       "2051    0.304699\n",
       "Name: propensity_score, Length: 2052, dtype: float64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propensity_df['propensity_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper2020_with_propensity = paper2020.merge(propensity_df,\n",
    "                                           on = 'paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper</th>\n",
       "      <th>authors</th>\n",
       "      <th>ratings</th>\n",
       "      <th>decisions</th>\n",
       "      <th>institution</th>\n",
       "      <th>csranking</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors_citations</th>\n",
       "      <th>authors_publications</th>\n",
       "      <th>authors_hindex</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "      <th>crazy</th>\n",
       "      <th>has_top_company</th>\n",
       "      <th>has_top_institution</th>\n",
       "      <th>propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>Pitfalls of In-Domain Uncertainty Estimation a...</td>\n",
       "      <td>Arsenii Ashukha;Alexander Lyzhov;Dmitry Molcha...</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Samsung;Skolkovo Institute of Science and Tech...</td>\n",
       "      <td>-1;-1;-1;481</td>\n",
       "      <td>0</td>\n",
       "      <td>488;12;481;2097</td>\n",
       "      <td>14;2;17;124</td>\n",
       "      <td>8;1;7;16</td>\n",
       "      <td>False</td>\n",
       "      <td>484.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.253127</td>\n",
       "      <td>-6.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>An Inductive Bias for Distances: Neural Nets t...</td>\n",
       "      <td>Silviu Pitis;Harris Chan;Kiarash Jamali;Jimmy Ba</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Department of Computer Science, University of ...</td>\n",
       "      <td>18;18;18;18</td>\n",
       "      <td>1;10</td>\n",
       "      <td>15;23;3;52924</td>\n",
       "      <td>9;13;3;56</td>\n",
       "      <td>2;3;1;22</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.975924</td>\n",
       "      <td>-6.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                              paper  \\\n",
       "0  2020  Pitfalls of In-Domain Uncertainty Estimation a...   \n",
       "1  2020  An Inductive Bias for Distances: Neural Nets t...   \n",
       "\n",
       "                                             authors   ratings decisions  \\\n",
       "0  Arsenii Ashukha;Alexander Lyzhov;Dmitry Molcha...  6.666667    Accept   \n",
       "1   Silviu Pitis;Harris Chan;Kiarash Jamali;Jimmy Ba  6.750000    Accept   \n",
       "\n",
       "                                         institution     csranking categories  \\\n",
       "0  Samsung;Skolkovo Institute of Science and Tech...  -1;-1;-1;481          0   \n",
       "1  Department of Computer Science, University of ...   18;18;18;18       1;10   \n",
       "\n",
       "  authors_citations authors_publications authors_hindex  arxiv  \\\n",
       "0   488;12;481;2097          14;2;17;124       8;1;7;16  False   \n",
       "1     15;23;3;52924            9;13;3;56       2;3;1;22  False   \n",
       "\n",
       "   authors_citations_median  authors_publications_median  \\\n",
       "0                     484.5                         15.5   \n",
       "1                      19.0                         11.0   \n",
       "\n",
       "   authors_hindex_median  reputation     crazy  has_top_company  \\\n",
       "0                    7.5    1.253127 -6.666667                0   \n",
       "1                    2.5    2.975924 -6.750000                0   \n",
       "\n",
       "   has_top_institution  propensity_score  \n",
       "0                    1          0.360486  \n",
       "1                    1          0.567842  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper2020_with_propensity.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is different because he is based on residual ??\n",
    "Tree vs classifier ?\n",
    "Je pense que la différence est qu'on n'utilise pas de training et test set dans le deuxieme car on va utiliser des cluster pour regrouper les data tandis que le premier on utilisait des tree ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2\n",
    "\n",
    "Now is time to match users! You will be implementing a technique called *caliper matching*. \n",
    "\n",
    "Create pairs of users as follows. For each treated subject (here a paper that was submitted to arxiv), find a non-treated subject (a paper that was not submitted to arxiv) with similar propensity score. Namely, if the propensity score of the treated unit is $p_t$, you must find a non-treated unit $p_c$ with propensity score $|p_{c} - p_t| < \\epsilon$. If there is no such a non-treated unit, you may ignore the treated unit and move forward with the matching. Notice that your output must be a 1-to-1 matching. So each paper can only be matched once.\n",
    "\n",
    "1. Perform this matching procedure using $\\epsilon = 0.05$.\n",
    "2. Report how many pairs did you manage to match? How many didn't you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimation(ptreat, pcontr):\n",
    "    ''' Return the estimator of the similarity between propensity score '''\n",
    "    return np.abs(pcontr-ptreat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(propensity_score1, propensity_score2):\n",
    "    '''Calculate similarity for instances with given propensity scores'''\n",
    "    return 1-np.abs(propensity_score1-propensity_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the treatment and control groups\n",
    "treatment_df = paper2020_with_propensity.loc[paper2020_with_propensity['arxiv']==True]\n",
    "control_df = paper2020_with_propensity.loc[paper2020_with_propensity['arxiv']==False]\n",
    "\n",
    "# Create an empty undirected graph\n",
    "G = nx.Graph()\n",
    "a=0\n",
    "# Loop through all the pairs of instances control 1 prepare to link all the treatment \n",
    "for treatment_id, treatment_row in treatment_df.iterrows():\n",
    "    for control_id, control_row in control_df.iterrows():\n",
    "            # Calculate the similarity \n",
    "            estimator = get_estimation(treatment_row['propensity_score'],\n",
    "                                      control_row['propensity_score'])\n",
    "            if estimator < 0.05:\n",
    "                # Add an edge between the two instances weighted by the similarity between them\n",
    "                G.add_weighted_edges_from([(treatment_id, control_id, -estimator)])\n",
    "                a=a+1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268046"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and return the maximum weight matching on the generated graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 4),\n",
       " (18, 935),\n",
       " (121, 148),\n",
       " (224, 269),\n",
       " (458, 70),\n",
       " (507, 1591),\n",
       " (580, 101),\n",
       " (600, 1673),\n",
       " (673, 454),\n",
       " (859, 683),\n",
       " (1015, 1359),\n",
       " (1024, 682),\n",
       " (1033, 1961),\n",
       " (1049, 1021),\n",
       " (1424, 1586),\n",
       " (1500, 1583),\n",
       " (1617, 851),\n",
       " (1691, 1612),\n",
       " (1746, 661),\n",
       " (1916, 1253)}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching = nx.max_weight_matching(G)\n",
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  590  pairs on 1462\n"
     ]
    }
   ],
   "source": [
    "print('We have ',len(matching),' pairs on',len(control_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "treatment_id=6\n",
    "matched_id=[1,5,7,8]\n",
    "if treatment_id not in matched_id:\n",
    "    print('ok')\n",
    "    \n",
    "matched_id.append(6)\n",
    "\n",
    "treatment_id=6\n",
    "if treatment_id not in matched_id:\n",
    "    print('ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.3\n",
    "\n",
    "Let's evaluate your matching! There are more rigorous ways to do it, but we'll go the easy path.\n",
    "\n",
    "\n",
    "1. Using one or several appropriate plot types, visualize the distributions of the variables reputation and ratings, for treated and non-treated subjects that you matched.\n",
    "2. Visualize the distributions of these variables for all papers from 2020 that appeared on arxiv, and all papers that did not (including those you did not manage to match).\n",
    "3. **Discuss:** According to your visual analysis (no statistical tests needed here), did the matching do a good job at balancing covariates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df_all = paper2020_with_propensity.iloc[[subj_id for t in matching for subj_id in t]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ratings</th>\n",
       "      <th>authors_citations_median</th>\n",
       "      <th>authors_publications_median</th>\n",
       "      <th>authors_hindex_median</th>\n",
       "      <th>reputation</th>\n",
       "      <th>crazy</th>\n",
       "      <th>has_top_company</th>\n",
       "      <th>has_top_institution</th>\n",
       "      <th>propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>2726.437500</td>\n",
       "      <td>49.487500</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.486144</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.319950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.282803</td>\n",
       "      <td>5338.841179</td>\n",
       "      <td>52.950568</td>\n",
       "      <td>13.511059</td>\n",
       "      <td>0.651057</td>\n",
       "      <td>5.595964</td>\n",
       "      <td>0.220721</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.086538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248886</td>\n",
       "      <td>-7.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>109.625000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.966454</td>\n",
       "      <td>-5.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.245244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.620260</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1353.250000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>17.125000</td>\n",
       "      <td>1.912496</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>21383.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.414047</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.456448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year    ratings  authors_citations_median  \\\n",
       "count    40.0  40.000000                 40.000000   \n",
       "mean   2020.0   4.800000               2726.437500   \n",
       "std       0.0   1.282803               5338.841179   \n",
       "min    2020.0   1.666667                  1.000000   \n",
       "25%    2020.0   4.000000                109.625000   \n",
       "50%    2020.0   5.000000                375.000000   \n",
       "75%    2020.0   5.750000               1353.250000   \n",
       "max    2020.0   7.333333              21383.000000   \n",
       "\n",
       "       authors_publications_median  authors_hindex_median  reputation  \\\n",
       "count                    40.000000              40.000000   40.000000   \n",
       "mean                     49.487500              13.050000    1.486144   \n",
       "std                      52.950568              13.511059    0.651057   \n",
       "min                       2.000000               1.000000    0.248886   \n",
       "25%                      16.750000               4.000000    0.966454   \n",
       "50%                      30.500000               8.000000    1.620260   \n",
       "75%                      55.500000              17.125000    1.912496   \n",
       "max                     198.000000              52.500000    2.414047   \n",
       "\n",
       "           crazy  has_top_company  has_top_institution  propensity_score  \n",
       "count  40.000000        40.000000            40.000000         40.000000  \n",
       "mean   -0.750000         0.050000             0.925000          0.319950  \n",
       "std     5.595964         0.220721             0.266747          0.086538  \n",
       "min    -7.333333         0.000000             0.000000          0.126457  \n",
       "25%    -5.750000         0.000000             1.000000          0.245244  \n",
       "50%    -5.000000         0.000000             1.000000          0.357249  \n",
       "75%     5.000000         0.000000             1.000000          0.380701  \n",
       "max     7.333333         1.000000             1.000000          0.456448  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "g = sns.FacetGrid(balanced_df_all, col='arxiv',margin_titles=True, height=5)\n",
    "g.map(plt.hist, 'reputation')\n",
    "plt.suptitle('Reputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(balanced_df_all, col='arxiv',margin_titles=True, height=5)\n",
    "g.map(plt.hist, 'ratings')\n",
    "plt.suptitle('Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Matching For both arvix = True and arvix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(paper2020_with_propensity, col='arxiv',margin_titles=True, height=5)\n",
    "g.map(plt.hist, 'reputation')\n",
    "plt.suptitle('Paper 2020 -> Reputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(paper2020_with_propensity, col='arxiv',margin_titles=True, height=5)\n",
    "g.map(plt.hist, 'ratings')\n",
    "plt.suptitle('Paper 2020 -> Reputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.4\n",
    "\n",
    "Finally, it's time to estimate the treatment effect. Given that we have pairs of matched samples, one that received treatment and one that did not, and that they have associated outcomes $y_{treat}$ and $y_{\\neg treat}$. We can calculate the average treatment effect as:\n",
    "\n",
    "$$\n",
    "ATE = \\frac{1}{N} \\sum_i^N  y_{treat}^{(i)} - y_{\\neg treat}^{(i)}\n",
    "$$\n",
    "\n",
    "Notice that here the outcome is a simple binary variable which equals 1 if the paper has been accepted and equals 0 if the paper has been rejected, and $N$ is the total number of matched samples in our analysis.\n",
    "\n",
    "According to your matched sample, estimate the treatment effect of publishing a paper on arxiv. \n",
    "### Report the 95% CI through bootstrapping.????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 4),\n",
       " (18, 935),\n",
       " (121, 148),\n",
       " (224, 269),\n",
       " (458, 70),\n",
       " (507, 1591),\n",
       " (580, 101),\n",
       " (600, 1673),\n",
       " (673, 454),\n",
       " (859, 683),\n",
       " (1015, 1359),\n",
       " (1024, 682),\n",
       " (1033, 1961),\n",
       " (1049, 1021),\n",
       " (1424, 1586),\n",
       " (1500, 1583),\n",
       " (1617, 851),\n",
       " (1691, 1612),\n",
       " (1746, 661),\n",
       " (1916, 1253)}"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_df_treat = balanced_df_all.loc[balanced_df_all['arxiv']==True].reset_index(drop=True)\n",
    "matching_df_control = balanced_df_all.loc[balanced_df_all['arxiv']==False].reset_index(drop=True)\n",
    "matching_df_treat['y_treat_treat'] = matching_df_treat['decisions'].apply(lambda x : 1 if x == 'Accept' else 0)\n",
    "matching_df_control['y_treat_control'] = matching_df_control['decisions'].apply(lambda x : 1 if x == 'Accept' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATE = (matching_df_treat ['y_treat_treat'] - matching_df_control['y_treat_control']).sum(\n",
    "    axis=0)/ matching_df_control['y_treat_control'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ate = 0.1\n"
     ]
    }
   ],
   "source": [
    "print('Ate =', ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.5\n",
    "\n",
    "Wait, but what about prestigious institutions? \n",
    "\n",
    "1.  To understand what is going on there, repeat tasks 3.2 to 3.4 considering *only* the top 10 institutions. Notice that you can use the same propensity scores and re-do the steps in a reduced dataframe containing only top-institutions.\n",
    "2. **Discuss:** Is this evidence that arxiv breaks double-blind submissions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 4),\n",
       " (18, 935),\n",
       " (121, 148),\n",
       " (224, 269),\n",
       " (458, 70),\n",
       " (507, 1591),\n",
       " (580, 101),\n",
       " (600, 1673),\n",
       " (673, 454),\n",
       " (1015, 1359),\n",
       " (1024, 682),\n",
       " (1033, 1961),\n",
       " (1049, 1021),\n",
       " (1500, 1583),\n",
       " (1617, 851),\n",
       " (1691, 1612),\n",
       " (1746, 661),\n",
       " (1916, 1253)}"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the treatment and control groups\n",
    "treatment_df = paper2020_with_propensity.loc[(paper2020_with_propensity['arxiv']==True) \n",
    "                                             & (paper2020_with_propensity['has_top_institution'] == 1) ]\n",
    "control_df = paper2020_with_propensity.loc[(paper2020_with_propensity['arxiv']==False)\n",
    "                                           & ((paper2020_with_propensity['has_top_institution'] == 1) ) ]\n",
    "\n",
    "# Create an empty undirected graph\n",
    "G = nx.Graph()\n",
    "matched_control_id=[]\n",
    "matched_treatment_id=[]\n",
    "# Loop through all the pairs of instances control 1 prepare to link all the treatment \n",
    "for treatment_id, treatment_row in treatment_df.iterrows():\n",
    "    for control_id, control_row in control_df.iterrows():\n",
    "            estimator = get_estimation(treatment_row['propensity_score'],\n",
    "                                      control_row['propensity_score'])\n",
    "            if estimator < 0.05:\n",
    "                # Add an edge between the two instances weighted by the similarity between them\n",
    "                G.add_weighted_edges_from([(control_id, treatment_id, -estimator)])\n",
    "\n",
    "# Generate and return the maximum weight matching on the generated graph\n",
    "matching = nx.max_weight_matching(G)\n",
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "balanced_df_all_top10 = paper2020_with_propensity.iloc[[subj_id for t in matching for subj_id in t]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_df_treat = balanced_df_all_top10.loc[balanced_df_all_top10['arxiv']==True].reset_index(drop=True)\n",
    "matching_df_control = balanced_df_all_top10.loc[balanced_df_all_top10['arxiv']==False].reset_index(drop=True)\n",
    "matching_df_treat['y_treat_treat'] = matching_df_treat['decisions'].apply(lambda x : 1 if x == 'Accept' else 0)\n",
    "matching_df_control['y_treat_control'] = matching_df_control['decisions'].apply(lambda x : 1 if x == 'Accept' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATE = (matching_df_treat ['y_treat_treat'] - matching_df_control['y_treat_control']).sum(\n",
    "    axis=0)/ matching_df_control['y_treat_control'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ate = 0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "print('Ate =', ATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
